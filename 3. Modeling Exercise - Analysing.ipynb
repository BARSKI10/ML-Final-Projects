{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bb7c4c-452a-408f-ac26-b184f1e10862",
   "metadata": {},
   "source": [
    "# Modeling exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbae80-7f28-4596-945e-a0784e384e4c",
   "metadata": {},
   "source": [
    "## General Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5650156-42a5-4fb7-b74a-dec08bafd6c1",
   "metadata": {},
   "source": [
    "* Submission date: 25.4.2022\n",
    "* Submission Method: Link to your solution notebook in [this sheet](https://docs.google.com/spreadsheets/d/1fTmjiVxzw_rM1hdh16enwUTtxzlHSJIiw41dJS2LKp0/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6850603-524a-4afc-a7a1-cba3eeeea1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e136158-e12c-4d15-9c47-3cd726054a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../Modles and Modeling/src')\n",
    "import numpy as np\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53824c3-ccb9-4f1b-9420-bb0b57509862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0716a6-a156-49a2-83d2-24d5ef36af3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7_/rd00750d2c32fj3338594q200000gp/T/ipykernel_20976/3822323994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_circles_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_moons_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import make_circles_dataframe, make_moons_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513df470-6d24-4611-9fe8-61c25397763a",
   "metadata": {},
   "source": [
    "## Fitting and Overfiting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e502f-4b12-4bf1-a981-7135b36e0830",
   "metadata": {},
   "source": [
    "The goal of the following exercise is to:\n",
    "* Observe overfitting due to insufficient data\n",
    "* Observe Overfitting due to overly complex model\n",
    "* Identify the overfitting point by looking at Train vs Test error dynamic\n",
    "* Observe how noise levels effect the needed data samples and model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b1cdc-fcfb-4ac7-841c-a5a534d569cd",
   "metadata": {},
   "source": [
    "To do so, you'll code an experiment in the first part, and analyze the experiment result in the second part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f343cc-0b25-4302-ab24-fc290c07b6ee",
   "metadata": {},
   "source": [
    "### Building an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a17e0-fb6f-479c-98bb-e5a6fc81e1ad",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "1. Create data of size N with noise level of magnitude NL from datasets DS_NAME. \n",
    "1. Split it to training and validation data (no need for test set), use 80%-20%. \n",
    "1. Use Logistic regression and Choose one complex model of your choice: [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), [SVM with RBF kernel](https://scikit-learn.org/stable/modules/svm.html) with different `gamma` values or [Random forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) with differnt number of `min_samples_split`. \n",
    "1. Train on the train set for different hyper parameter values. compute:\n",
    "   1. Classification accuracy on the training set (TRE)\n",
    "   1. Classification accuracy on the validation set (TESTE)\n",
    "   1. The difference beteen the two above (E_DIFF)\n",
    "1. Save DS_NAME, N, NL, CLF_NAME, K, TRE, TESTE, E_DIFF and the regularization/hyper param (K, gamma or min_samples_split and regularization value for the linear regression classifier)\n",
    "\n",
    "Repeat for:\n",
    "* DS_NAME in Moons, Circles\n",
    "* N (number of samples) in [5, 10, 50, 100, 1000, 10000]\n",
    "* NL (noise level) in [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "* For the complex model: 10 Values of hyper parameter of the complex model you've chosen.\n",
    "* For the linear model: 5 values of ridge (l2) regularization - [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "**NOTE:** The Result DataFrame *size* shoule, for running each Model, is 510. For TOW models its size is 1,020 (for THREE 1,530)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e0146-9c7a-4cf1-a83e-da9a11bcc796",
   "metadata": {},
   "source": [
    "### Analysing the expermient results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39e9c4-0332-4564-a674-52b99332ecfd",
   "metadata": {},
   "source": [
    "1. For SVM only, For dataset of size 10k and for each dataset, What are the best model params? How stable is it? \n",
    "1. For SVM only, For dataset of size 10k and for each dataset, What is the most stable model and model params? How good is it in comparison to other models? Explain using bias and variance terminoligy.\n",
    "1. Does regularization help for linear models? consider different datasets sizes. \n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing data sizes? (answer for svm and LR seperatly)\n",
    "1. For a given noise level of your chioce, How does the train, test and difference error changes with increasing model complexity? (answer for svm and LR seperatly)\n",
    "1. Does the Noise Level (NL) effect the number of datapoints needed to reach optimal test results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fa350-4106-419c-9020-51986a0a716d",
   "metadata": {},
   "source": [
    "Bonus:\n",
    "\n",
    "* For SVM: Select one dataset and with 0.2 noise level. Identify the optimal model params, and visualize the decision boundry learned. \n",
    "  * Hint: Use a grid. See classification models notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf7262-12b1-4417-acd2-eb8365b04b11",
   "metadata": {},
   "source": [
    "## Tips and Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4522e-a8e9-4476-90ac-d1a2679085f4",
   "metadata": {},
   "source": [
    "For buliding the experiment:\n",
    "\n",
    "* Start with one dataframe holding all the data for both datastes with different noise level. Use the `make_<dataset_name>_dataframe()` functions below, and add two columns, dataset_name and noise_level, before appending the new dataset to the rest of the datasets. Use `df = pd.DataFrame()` to start with an empty dataframe and using a loop, add data to it using `df = df.append(<the needed df here>)`. Verify that you have 10k samples for each dataset type and noise level by a proper `.value_counts()`. You can modify the \n",
    "* When you'll need an N samples data with a specific noise level, use `query()` and `head(n)` to get the needed dataset. \n",
    "* Use sklearn `train_test_split()` method to split the data with `test_size` and `random_state` parameters set correctly to ensure you are always splitting the data the same way for a given fold `k`. Read [the docs](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) if needed. \n",
    "* You can also not create your own data splitter, and instead use `model_selection.cross_validate()` from sklearn. You'll need to ask for the train erros as well as the test errors, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html).\n",
    "* Use prints in proper location to ensure the progress of the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f130c6-62ba-4490-983d-1d63470dc615",
   "metadata": {},
   "source": [
    "**If you get stuck, and need refernce, scroll to the end of the notebook to see more hints!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ffe8f-8c0b-4dc3-9cc2-9c3dc02852d7",
   "metadata": {},
   "source": [
    "## Moons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a6b4c61-454e-4887-963f-61d5ec6bc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7392ae8f-32a7-4c77-a5be-34043ecd09ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.975602</td>\n",
       "      <td>0.458461</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.610984</td>\n",
       "      <td>1.014617</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.642946</td>\n",
       "      <td>0.940368</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.485465</td>\n",
       "      <td>-0.403386</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718501</td>\n",
       "      <td>-0.536166</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y label\n",
       "0  1.975602  0.458461     B\n",
       "1  0.610984  1.014617     A\n",
       "2 -0.642946  0.940368     A\n",
       "3  0.485465 -0.403386     B\n",
       "4  0.718501 -0.536166     B"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moons_df = make_moons_dataframe(n_samples=1000, noise_level=0.1)\n",
    "moons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c4d95c-3cad-4596-a8b3-29d67aa9859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f8b234bb9640ec8772e24fcc3dc4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='noise_level', max=0.5, step=0.05), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def plot_noisy_moons(noise_level = widgets.FloatSlider(value=0, min=0, max=0.5, step=0.05)):\n",
    "    moons_df = make_moons_dataframe(n_samples=1000, noise_level=noise_level)\n",
    "    return px.scatter(moons_df, x='x', y='y', color = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da16a2e2-11b0-461b-b370-b14a915078d4",
   "metadata": {},
   "source": [
    "## Circles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b1498d-60e1-429e-a122-f120f5ed5720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.509939</td>\n",
       "      <td>0.616411</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.719524</td>\n",
       "      <td>-0.349693</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799747</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.974527</td>\n",
       "      <td>0.224271</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675333</td>\n",
       "      <td>-0.737513</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y label\n",
       "0 -0.509939  0.616411     B\n",
       "1  0.719524 -0.349693     B\n",
       "2  0.799747  0.020104     B\n",
       "3 -0.974527  0.224271     A\n",
       "4  0.675333 -0.737513     A"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles_df = make_circles_dataframe(n_samples=500, noise_level=0)\n",
    "circles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ef522a-e381-42e1-b321-31b3d2f3b0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a17ba3c4704afcb125f4aaa28f6bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='noise_level', max=0.5, step=0.05), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def plot_noisy_circles(noise_level = widgets.FloatSlider(value=0, min=0, max=0.5, step=0.05)):\n",
    "    df = make_circles_dataframe(1000, noise_level)\n",
    "    return px.scatter(df, x='x', y='y', color = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fed2a5-29d9-41a3-b086-76985a174cd5",
   "metadata": {},
   "source": [
    "## SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e97090-67ac-4e04-8bb3-eb2f7cdc5bd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Creating MOONs and CIRCLEs Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad18e7fb-87f5-4a42-9f67-6e0098f20eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [10, 50, 100, 1000, 10000] # Because in 5 observations samples there are times that the data doesn't include both labels, we decided to execute the experiment with 10 observations and up.\n",
    "noise_level = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "ds_name = ['Moon', 'Circle']\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ef998e-3530-4550-823b-a880a89b8a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds_name  noise_level\n",
       "Circle   0.0            10000\n",
       "         0.1            10000\n",
       "         0.2            10000\n",
       "         0.3            10000\n",
       "         0.4            10000\n",
       "         0.5            10000\n",
       "Moon     0.0            10000\n",
       "         0.1            10000\n",
       "         0.2            10000\n",
       "         0.3            10000\n",
       "         0.4            10000\n",
       "         0.5            10000\n",
       "Name: noise_level, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for typush in ds_name:\n",
    "    if typush == 'Moon':\n",
    "        for nl in noise_level:\n",
    "            temp_df = make_moons_dataframe(n_samples = 10000, noise_level = nl)\n",
    "            temp_df['noise_level'] = nl\n",
    "            temp_df['ds_name'] = typush\n",
    "            df = df.append(temp_df)\n",
    "    elif typush == 'Circle':\n",
    "        for nl in noise_level:\n",
    "            temp_df = make_circles_dataframe(n_samples = 10000, noise_level = nl)\n",
    "            temp_df['noise_level'] = nl\n",
    "            temp_df['ds_name'] = typush\n",
    "            df = df.append(temp_df)\n",
    "            \n",
    "df.groupby('ds_name').noise_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "0e7e7abc-091c-4643-98d1-8ea7aca1b615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>ds_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.704324</td>\n",
       "      <td>0.709879</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.741221</td>\n",
       "      <td>-0.171261</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.516955</td>\n",
       "      <td>-0.356013</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.828072</td>\n",
       "      <td>0.560622</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.056844</td>\n",
       "      <td>-0.498383</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y label  noise_level ds_name\n",
       "0 -0.704324  0.709879     A          0.0    Moon\n",
       "1  1.741221 -0.171261     B          0.0    Moon\n",
       "2  1.516955 -0.356013     B          0.0    Moon\n",
       "3 -0.828072  0.560622     A          0.0    Moon\n",
       "4  1.056844 -0.498383     B          0.0    Moon"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5160b-4fed-40e0-bf59-c9911de4b088",
   "metadata": {},
   "source": [
    "### 2. Running Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9af02c-723a-4673-81ac-798d829c2fdb",
   "metadata": {},
   "source": [
    "Before we beging the Hyper Parameter Search (HPS), we should choose the most appropriate **Evaluation Tool**. Our Data is balaced and there is no \"favorite\" label we prefer increase its Identification. Therefore we will ues **ACCURACY** as our evloation tool.\n",
    "\n",
    "**MODELS:**\n",
    "1. Logistic Regression (**logit**), as Linear Model, uses as *Low Capcity* Model in this paper.\n",
    "1. Support Vector Machine (**SVM**), as more Complex model, uses as *High Capcity* Model in this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32d40a-2eb9-46c9-85d7-b065ac9f07ef",
   "metadata": {},
   "source": [
    "**NOTES**:\n",
    "* When the size sample (n_sample) is extremely small, it is more than possible that the sample would contain observations from one lablel only. In that case, the function `cross_validate()` dosent work. Therefore we decided not to use 5-size samples and run the models with 10, 50, 100, 1000, and 10000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64213f75-4198-4727-9b62-062dd650fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1bf889-f939-4e18-8172-e41f53d4ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clfs = ['svm', 'logit']\n",
    "cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001 ,0.005, 0.01 ,0.1, 0.5, 1 ,5 , 10, 100, 1000]\n",
    "k_fold = KFold(n_splits = 5)\n",
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f83db10c-5b3c-4b1d-9eb6-3c94418ddbbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) svm, gamma = 0.001, Moon dataset, 0 noise level, 10 observations\n",
      "2) svm, gamma = 0.005, Moon dataset, 0 noise level, 10 observations\n",
      "3) svm, gamma = 0.01, Moon dataset, 0 noise level, 10 observations\n",
      "4) svm, gamma = 0.1, Moon dataset, 0 noise level, 10 observations\n",
      "5) svm, gamma = 0.5, Moon dataset, 0 noise level, 10 observations\n",
      "6) svm, gamma = 1, Moon dataset, 0 noise level, 10 observations\n",
      "7) svm, gamma = 5, Moon dataset, 0 noise level, 10 observations\n",
      "8) svm, gamma = 10, Moon dataset, 0 noise level, 10 observations\n",
      "9) svm, gamma = 100, Moon dataset, 0 noise level, 10 observations\n",
      "10) svm, gamma = 1000, Moon dataset, 0 noise level, 10 observations\n",
      "11) svm, gamma = 0.001, Moon dataset, 0.1 noise level, 10 observations\n",
      "12) svm, gamma = 0.005, Moon dataset, 0.1 noise level, 10 observations\n",
      "13) svm, gamma = 0.01, Moon dataset, 0.1 noise level, 10 observations\n",
      "14) svm, gamma = 0.1, Moon dataset, 0.1 noise level, 10 observations\n",
      "15) svm, gamma = 0.5, Moon dataset, 0.1 noise level, 10 observations\n",
      "16) svm, gamma = 1, Moon dataset, 0.1 noise level, 10 observations\n",
      "17) svm, gamma = 5, Moon dataset, 0.1 noise level, 10 observations\n",
      "18) svm, gamma = 10, Moon dataset, 0.1 noise level, 10 observations\n",
      "19) svm, gamma = 100, Moon dataset, 0.1 noise level, 10 observations\n",
      "20) svm, gamma = 1000, Moon dataset, 0.1 noise level, 10 observations\n",
      "21) svm, gamma = 0.001, Moon dataset, 0.2 noise level, 10 observations\n",
      "22) svm, gamma = 0.005, Moon dataset, 0.2 noise level, 10 observations\n",
      "23) svm, gamma = 0.01, Moon dataset, 0.2 noise level, 10 observations\n",
      "24) svm, gamma = 0.1, Moon dataset, 0.2 noise level, 10 observations\n",
      "25) svm, gamma = 0.5, Moon dataset, 0.2 noise level, 10 observations\n",
      "26) svm, gamma = 1, Moon dataset, 0.2 noise level, 10 observations\n",
      "27) svm, gamma = 5, Moon dataset, 0.2 noise level, 10 observations\n",
      "28) svm, gamma = 10, Moon dataset, 0.2 noise level, 10 observations\n",
      "29) svm, gamma = 100, Moon dataset, 0.2 noise level, 10 observations\n",
      "30) svm, gamma = 1000, Moon dataset, 0.2 noise level, 10 observations\n",
      "31) svm, gamma = 0.001, Moon dataset, 0.3 noise level, 10 observations\n",
      "32) svm, gamma = 0.005, Moon dataset, 0.3 noise level, 10 observations\n",
      "33) svm, gamma = 0.01, Moon dataset, 0.3 noise level, 10 observations\n",
      "34) svm, gamma = 0.1, Moon dataset, 0.3 noise level, 10 observations\n",
      "35) svm, gamma = 0.5, Moon dataset, 0.3 noise level, 10 observations\n",
      "36) svm, gamma = 1, Moon dataset, 0.3 noise level, 10 observations\n",
      "37) svm, gamma = 5, Moon dataset, 0.3 noise level, 10 observations\n",
      "38) svm, gamma = 10, Moon dataset, 0.3 noise level, 10 observations\n",
      "39) svm, gamma = 100, Moon dataset, 0.3 noise level, 10 observations\n",
      "40) svm, gamma = 1000, Moon dataset, 0.3 noise level, 10 observations\n",
      "41) svm, gamma = 0.001, Moon dataset, 0.4 noise level, 10 observations\n",
      "42) svm, gamma = 0.005, Moon dataset, 0.4 noise level, 10 observations\n",
      "43) svm, gamma = 0.01, Moon dataset, 0.4 noise level, 10 observations\n",
      "44) svm, gamma = 0.1, Moon dataset, 0.4 noise level, 10 observations\n",
      "45) svm, gamma = 0.5, Moon dataset, 0.4 noise level, 10 observations\n",
      "46) svm, gamma = 1, Moon dataset, 0.4 noise level, 10 observations\n",
      "47) svm, gamma = 5, Moon dataset, 0.4 noise level, 10 observations\n",
      "48) svm, gamma = 10, Moon dataset, 0.4 noise level, 10 observations\n",
      "49) svm, gamma = 100, Moon dataset, 0.4 noise level, 10 observations\n",
      "50) svm, gamma = 1000, Moon dataset, 0.4 noise level, 10 observations\n",
      "51) svm, gamma = 0.001, Moon dataset, 0.5 noise level, 10 observations\n",
      "52) svm, gamma = 0.005, Moon dataset, 0.5 noise level, 10 observations\n",
      "53) svm, gamma = 0.01, Moon dataset, 0.5 noise level, 10 observations\n",
      "54) svm, gamma = 0.1, Moon dataset, 0.5 noise level, 10 observations\n",
      "55) svm, gamma = 0.5, Moon dataset, 0.5 noise level, 10 observations\n",
      "56) svm, gamma = 1, Moon dataset, 0.5 noise level, 10 observations\n",
      "57) svm, gamma = 5, Moon dataset, 0.5 noise level, 10 observations\n",
      "58) svm, gamma = 10, Moon dataset, 0.5 noise level, 10 observations\n",
      "59) svm, gamma = 100, Moon dataset, 0.5 noise level, 10 observations\n",
      "60) svm, gamma = 1000, Moon dataset, 0.5 noise level, 10 observations\n",
      "61) svm, gamma = 0.001, Moon dataset, 0 noise level, 50 observations\n",
      "62) svm, gamma = 0.005, Moon dataset, 0 noise level, 50 observations\n",
      "63) svm, gamma = 0.01, Moon dataset, 0 noise level, 50 observations\n",
      "64) svm, gamma = 0.1, Moon dataset, 0 noise level, 50 observations\n",
      "65) svm, gamma = 0.5, Moon dataset, 0 noise level, 50 observations\n",
      "66) svm, gamma = 1, Moon dataset, 0 noise level, 50 observations\n",
      "67) svm, gamma = 5, Moon dataset, 0 noise level, 50 observations\n",
      "68) svm, gamma = 10, Moon dataset, 0 noise level, 50 observations\n",
      "69) svm, gamma = 100, Moon dataset, 0 noise level, 50 observations\n",
      "70) svm, gamma = 1000, Moon dataset, 0 noise level, 50 observations\n",
      "71) svm, gamma = 0.001, Moon dataset, 0.1 noise level, 50 observations\n",
      "72) svm, gamma = 0.005, Moon dataset, 0.1 noise level, 50 observations\n",
      "73) svm, gamma = 0.01, Moon dataset, 0.1 noise level, 50 observations\n",
      "74) svm, gamma = 0.1, Moon dataset, 0.1 noise level, 50 observations\n",
      "75) svm, gamma = 0.5, Moon dataset, 0.1 noise level, 50 observations\n",
      "76) svm, gamma = 1, Moon dataset, 0.1 noise level, 50 observations\n",
      "77) svm, gamma = 5, Moon dataset, 0.1 noise level, 50 observations\n",
      "78) svm, gamma = 10, Moon dataset, 0.1 noise level, 50 observations\n",
      "79) svm, gamma = 100, Moon dataset, 0.1 noise level, 50 observations\n",
      "80) svm, gamma = 1000, Moon dataset, 0.1 noise level, 50 observations\n",
      "81) svm, gamma = 0.001, Moon dataset, 0.2 noise level, 50 observations\n",
      "82) svm, gamma = 0.005, Moon dataset, 0.2 noise level, 50 observations\n",
      "83) svm, gamma = 0.01, Moon dataset, 0.2 noise level, 50 observations\n",
      "84) svm, gamma = 0.1, Moon dataset, 0.2 noise level, 50 observations\n",
      "85) svm, gamma = 0.5, Moon dataset, 0.2 noise level, 50 observations\n",
      "86) svm, gamma = 1, Moon dataset, 0.2 noise level, 50 observations\n",
      "87) svm, gamma = 5, Moon dataset, 0.2 noise level, 50 observations\n",
      "88) svm, gamma = 10, Moon dataset, 0.2 noise level, 50 observations\n",
      "89) svm, gamma = 100, Moon dataset, 0.2 noise level, 50 observations\n",
      "90) svm, gamma = 1000, Moon dataset, 0.2 noise level, 50 observations\n",
      "91) svm, gamma = 0.001, Moon dataset, 0.3 noise level, 50 observations\n",
      "92) svm, gamma = 0.005, Moon dataset, 0.3 noise level, 50 observations\n",
      "93) svm, gamma = 0.01, Moon dataset, 0.3 noise level, 50 observations\n",
      "94) svm, gamma = 0.1, Moon dataset, 0.3 noise level, 50 observations\n",
      "95) svm, gamma = 0.5, Moon dataset, 0.3 noise level, 50 observations\n",
      "96) svm, gamma = 1, Moon dataset, 0.3 noise level, 50 observations\n",
      "97) svm, gamma = 5, Moon dataset, 0.3 noise level, 50 observations\n",
      "98) svm, gamma = 10, Moon dataset, 0.3 noise level, 50 observations\n",
      "99) svm, gamma = 100, Moon dataset, 0.3 noise level, 50 observations\n",
      "100) svm, gamma = 1000, Moon dataset, 0.3 noise level, 50 observations\n",
      "101) svm, gamma = 0.001, Moon dataset, 0.4 noise level, 50 observations\n",
      "102) svm, gamma = 0.005, Moon dataset, 0.4 noise level, 50 observations\n",
      "103) svm, gamma = 0.01, Moon dataset, 0.4 noise level, 50 observations\n",
      "104) svm, gamma = 0.1, Moon dataset, 0.4 noise level, 50 observations\n",
      "105) svm, gamma = 0.5, Moon dataset, 0.4 noise level, 50 observations\n",
      "106) svm, gamma = 1, Moon dataset, 0.4 noise level, 50 observations\n",
      "107) svm, gamma = 5, Moon dataset, 0.4 noise level, 50 observations\n",
      "108) svm, gamma = 10, Moon dataset, 0.4 noise level, 50 observations\n",
      "109) svm, gamma = 100, Moon dataset, 0.4 noise level, 50 observations\n",
      "110) svm, gamma = 1000, Moon dataset, 0.4 noise level, 50 observations\n",
      "111) svm, gamma = 0.001, Moon dataset, 0.5 noise level, 50 observations\n",
      "112) svm, gamma = 0.005, Moon dataset, 0.5 noise level, 50 observations\n",
      "113) svm, gamma = 0.01, Moon dataset, 0.5 noise level, 50 observations\n",
      "114) svm, gamma = 0.1, Moon dataset, 0.5 noise level, 50 observations\n",
      "115) svm, gamma = 0.5, Moon dataset, 0.5 noise level, 50 observations\n",
      "116) svm, gamma = 1, Moon dataset, 0.5 noise level, 50 observations\n",
      "117) svm, gamma = 5, Moon dataset, 0.5 noise level, 50 observations\n",
      "118) svm, gamma = 10, Moon dataset, 0.5 noise level, 50 observations\n",
      "119) svm, gamma = 100, Moon dataset, 0.5 noise level, 50 observations\n",
      "120) svm, gamma = 1000, Moon dataset, 0.5 noise level, 50 observations\n",
      "121) svm, gamma = 0.001, Moon dataset, 0 noise level, 100 observations\n",
      "122) svm, gamma = 0.005, Moon dataset, 0 noise level, 100 observations\n",
      "123) svm, gamma = 0.01, Moon dataset, 0 noise level, 100 observations\n",
      "124) svm, gamma = 0.1, Moon dataset, 0 noise level, 100 observations\n",
      "125) svm, gamma = 0.5, Moon dataset, 0 noise level, 100 observations\n",
      "126) svm, gamma = 1, Moon dataset, 0 noise level, 100 observations\n",
      "127) svm, gamma = 5, Moon dataset, 0 noise level, 100 observations\n",
      "128) svm, gamma = 10, Moon dataset, 0 noise level, 100 observations\n",
      "129) svm, gamma = 100, Moon dataset, 0 noise level, 100 observations\n",
      "130) svm, gamma = 1000, Moon dataset, 0 noise level, 100 observations\n",
      "131) svm, gamma = 0.001, Moon dataset, 0.1 noise level, 100 observations\n",
      "132) svm, gamma = 0.005, Moon dataset, 0.1 noise level, 100 observations\n",
      "133) svm, gamma = 0.01, Moon dataset, 0.1 noise level, 100 observations\n",
      "134) svm, gamma = 0.1, Moon dataset, 0.1 noise level, 100 observations\n",
      "135) svm, gamma = 0.5, Moon dataset, 0.1 noise level, 100 observations\n",
      "136) svm, gamma = 1, Moon dataset, 0.1 noise level, 100 observations\n",
      "137) svm, gamma = 5, Moon dataset, 0.1 noise level, 100 observations\n",
      "138) svm, gamma = 10, Moon dataset, 0.1 noise level, 100 observations\n",
      "139) svm, gamma = 100, Moon dataset, 0.1 noise level, 100 observations\n",
      "140) svm, gamma = 1000, Moon dataset, 0.1 noise level, 100 observations\n",
      "141) svm, gamma = 0.001, Moon dataset, 0.2 noise level, 100 observations\n",
      "142) svm, gamma = 0.005, Moon dataset, 0.2 noise level, 100 observations\n",
      "143) svm, gamma = 0.01, Moon dataset, 0.2 noise level, 100 observations\n",
      "144) svm, gamma = 0.1, Moon dataset, 0.2 noise level, 100 observations\n",
      "145) svm, gamma = 0.5, Moon dataset, 0.2 noise level, 100 observations\n",
      "146) svm, gamma = 1, Moon dataset, 0.2 noise level, 100 observations\n",
      "147) svm, gamma = 5, Moon dataset, 0.2 noise level, 100 observations\n",
      "148) svm, gamma = 10, Moon dataset, 0.2 noise level, 100 observations\n",
      "149) svm, gamma = 100, Moon dataset, 0.2 noise level, 100 observations\n",
      "150) svm, gamma = 1000, Moon dataset, 0.2 noise level, 100 observations\n",
      "151) svm, gamma = 0.001, Moon dataset, 0.3 noise level, 100 observations\n",
      "152) svm, gamma = 0.005, Moon dataset, 0.3 noise level, 100 observations\n",
      "153) svm, gamma = 0.01, Moon dataset, 0.3 noise level, 100 observations\n",
      "154) svm, gamma = 0.1, Moon dataset, 0.3 noise level, 100 observations\n",
      "155) svm, gamma = 0.5, Moon dataset, 0.3 noise level, 100 observations\n",
      "156) svm, gamma = 1, Moon dataset, 0.3 noise level, 100 observations\n",
      "157) svm, gamma = 5, Moon dataset, 0.3 noise level, 100 observations\n",
      "158) svm, gamma = 10, Moon dataset, 0.3 noise level, 100 observations\n",
      "159) svm, gamma = 100, Moon dataset, 0.3 noise level, 100 observations\n",
      "160) svm, gamma = 1000, Moon dataset, 0.3 noise level, 100 observations\n",
      "161) svm, gamma = 0.001, Moon dataset, 0.4 noise level, 100 observations\n",
      "162) svm, gamma = 0.005, Moon dataset, 0.4 noise level, 100 observations\n",
      "163) svm, gamma = 0.01, Moon dataset, 0.4 noise level, 100 observations\n",
      "164) svm, gamma = 0.1, Moon dataset, 0.4 noise level, 100 observations\n",
      "165) svm, gamma = 0.5, Moon dataset, 0.4 noise level, 100 observations\n",
      "166) svm, gamma = 1, Moon dataset, 0.4 noise level, 100 observations\n",
      "167) svm, gamma = 5, Moon dataset, 0.4 noise level, 100 observations\n",
      "168) svm, gamma = 10, Moon dataset, 0.4 noise level, 100 observations\n",
      "169) svm, gamma = 100, Moon dataset, 0.4 noise level, 100 observations\n",
      "170) svm, gamma = 1000, Moon dataset, 0.4 noise level, 100 observations\n",
      "171) svm, gamma = 0.001, Moon dataset, 0.5 noise level, 100 observations\n",
      "172) svm, gamma = 0.005, Moon dataset, 0.5 noise level, 100 observations\n",
      "173) svm, gamma = 0.01, Moon dataset, 0.5 noise level, 100 observations\n",
      "174) svm, gamma = 0.1, Moon dataset, 0.5 noise level, 100 observations\n",
      "175) svm, gamma = 0.5, Moon dataset, 0.5 noise level, 100 observations\n",
      "176) svm, gamma = 1, Moon dataset, 0.5 noise level, 100 observations\n",
      "177) svm, gamma = 5, Moon dataset, 0.5 noise level, 100 observations\n",
      "178) svm, gamma = 10, Moon dataset, 0.5 noise level, 100 observations\n",
      "179) svm, gamma = 100, Moon dataset, 0.5 noise level, 100 observations\n",
      "180) svm, gamma = 1000, Moon dataset, 0.5 noise level, 100 observations\n",
      "181) svm, gamma = 0.001, Moon dataset, 0 noise level, 1000 observations\n",
      "182) svm, gamma = 0.005, Moon dataset, 0 noise level, 1000 observations\n",
      "183) svm, gamma = 0.01, Moon dataset, 0 noise level, 1000 observations\n",
      "184) svm, gamma = 0.1, Moon dataset, 0 noise level, 1000 observations\n",
      "185) svm, gamma = 0.5, Moon dataset, 0 noise level, 1000 observations\n",
      "186) svm, gamma = 1, Moon dataset, 0 noise level, 1000 observations\n",
      "187) svm, gamma = 5, Moon dataset, 0 noise level, 1000 observations\n",
      "188) svm, gamma = 10, Moon dataset, 0 noise level, 1000 observations\n",
      "189) svm, gamma = 100, Moon dataset, 0 noise level, 1000 observations\n",
      "190) svm, gamma = 1000, Moon dataset, 0 noise level, 1000 observations\n",
      "191) svm, gamma = 0.001, Moon dataset, 0.1 noise level, 1000 observations\n",
      "192) svm, gamma = 0.005, Moon dataset, 0.1 noise level, 1000 observations\n",
      "193) svm, gamma = 0.01, Moon dataset, 0.1 noise level, 1000 observations\n",
      "194) svm, gamma = 0.1, Moon dataset, 0.1 noise level, 1000 observations\n",
      "195) svm, gamma = 0.5, Moon dataset, 0.1 noise level, 1000 observations\n",
      "196) svm, gamma = 1, Moon dataset, 0.1 noise level, 1000 observations\n",
      "197) svm, gamma = 5, Moon dataset, 0.1 noise level, 1000 observations\n",
      "198) svm, gamma = 10, Moon dataset, 0.1 noise level, 1000 observations\n",
      "199) svm, gamma = 100, Moon dataset, 0.1 noise level, 1000 observations\n",
      "200) svm, gamma = 1000, Moon dataset, 0.1 noise level, 1000 observations\n",
      "201) svm, gamma = 0.001, Moon dataset, 0.2 noise level, 1000 observations\n",
      "202) svm, gamma = 0.005, Moon dataset, 0.2 noise level, 1000 observations\n",
      "203) svm, gamma = 0.01, Moon dataset, 0.2 noise level, 1000 observations\n",
      "204) svm, gamma = 0.1, Moon dataset, 0.2 noise level, 1000 observations\n",
      "205) svm, gamma = 0.5, Moon dataset, 0.2 noise level, 1000 observations\n",
      "206) svm, gamma = 1, Moon dataset, 0.2 noise level, 1000 observations\n",
      "207) svm, gamma = 5, Moon dataset, 0.2 noise level, 1000 observations\n",
      "208) svm, gamma = 10, Moon dataset, 0.2 noise level, 1000 observations\n",
      "209) svm, gamma = 100, Moon dataset, 0.2 noise level, 1000 observations\n",
      "210) svm, gamma = 1000, Moon dataset, 0.2 noise level, 1000 observations\n",
      "211) svm, gamma = 0.001, Moon dataset, 0.3 noise level, 1000 observations\n",
      "212) svm, gamma = 0.005, Moon dataset, 0.3 noise level, 1000 observations\n",
      "213) svm, gamma = 0.01, Moon dataset, 0.3 noise level, 1000 observations\n",
      "214) svm, gamma = 0.1, Moon dataset, 0.3 noise level, 1000 observations\n",
      "215) svm, gamma = 0.5, Moon dataset, 0.3 noise level, 1000 observations\n",
      "216) svm, gamma = 1, Moon dataset, 0.3 noise level, 1000 observations\n",
      "217) svm, gamma = 5, Moon dataset, 0.3 noise level, 1000 observations\n",
      "218) svm, gamma = 10, Moon dataset, 0.3 noise level, 1000 observations\n",
      "219) svm, gamma = 100, Moon dataset, 0.3 noise level, 1000 observations\n",
      "220) svm, gamma = 1000, Moon dataset, 0.3 noise level, 1000 observations\n",
      "221) svm, gamma = 0.001, Moon dataset, 0.4 noise level, 1000 observations\n",
      "222) svm, gamma = 0.005, Moon dataset, 0.4 noise level, 1000 observations\n",
      "223) svm, gamma = 0.01, Moon dataset, 0.4 noise level, 1000 observations\n",
      "224) svm, gamma = 0.1, Moon dataset, 0.4 noise level, 1000 observations\n",
      "225) svm, gamma = 0.5, Moon dataset, 0.4 noise level, 1000 observations\n",
      "226) svm, gamma = 1, Moon dataset, 0.4 noise level, 1000 observations\n",
      "227) svm, gamma = 5, Moon dataset, 0.4 noise level, 1000 observations\n",
      "228) svm, gamma = 10, Moon dataset, 0.4 noise level, 1000 observations\n",
      "229) svm, gamma = 100, Moon dataset, 0.4 noise level, 1000 observations\n",
      "230) svm, gamma = 1000, Moon dataset, 0.4 noise level, 1000 observations\n",
      "231) svm, gamma = 0.001, Moon dataset, 0.5 noise level, 1000 observations\n",
      "232) svm, gamma = 0.005, Moon dataset, 0.5 noise level, 1000 observations\n",
      "233) svm, gamma = 0.01, Moon dataset, 0.5 noise level, 1000 observations\n",
      "234) svm, gamma = 0.1, Moon dataset, 0.5 noise level, 1000 observations\n",
      "235) svm, gamma = 0.5, Moon dataset, 0.5 noise level, 1000 observations\n",
      "236) svm, gamma = 1, Moon dataset, 0.5 noise level, 1000 observations\n",
      "237) svm, gamma = 5, Moon dataset, 0.5 noise level, 1000 observations\n",
      "238) svm, gamma = 10, Moon dataset, 0.5 noise level, 1000 observations\n",
      "239) svm, gamma = 100, Moon dataset, 0.5 noise level, 1000 observations\n",
      "240) svm, gamma = 1000, Moon dataset, 0.5 noise level, 1000 observations\n",
      "241) svm, gamma = 0.001, Moon dataset, 0 noise level, 10000 observations\n",
      "242) svm, gamma = 0.005, Moon dataset, 0 noise level, 10000 observations\n",
      "243) svm, gamma = 0.01, Moon dataset, 0 noise level, 10000 observations\n",
      "244) svm, gamma = 0.1, Moon dataset, 0 noise level, 10000 observations\n",
      "245) svm, gamma = 0.5, Moon dataset, 0 noise level, 10000 observations\n",
      "246) svm, gamma = 1, Moon dataset, 0 noise level, 10000 observations\n",
      "247) svm, gamma = 5, Moon dataset, 0 noise level, 10000 observations\n",
      "248) svm, gamma = 10, Moon dataset, 0 noise level, 10000 observations\n",
      "249) svm, gamma = 100, Moon dataset, 0 noise level, 10000 observations\n",
      "250) svm, gamma = 1000, Moon dataset, 0 noise level, 10000 observations\n",
      "251) svm, gamma = 0.001, Moon dataset, 0.1 noise level, 10000 observations\n",
      "252) svm, gamma = 0.005, Moon dataset, 0.1 noise level, 10000 observations\n",
      "253) svm, gamma = 0.01, Moon dataset, 0.1 noise level, 10000 observations\n",
      "254) svm, gamma = 0.1, Moon dataset, 0.1 noise level, 10000 observations\n",
      "255) svm, gamma = 0.5, Moon dataset, 0.1 noise level, 10000 observations\n",
      "256) svm, gamma = 1, Moon dataset, 0.1 noise level, 10000 observations\n",
      "257) svm, gamma = 5, Moon dataset, 0.1 noise level, 10000 observations\n",
      "258) svm, gamma = 10, Moon dataset, 0.1 noise level, 10000 observations\n",
      "259) svm, gamma = 100, Moon dataset, 0.1 noise level, 10000 observations\n",
      "260) svm, gamma = 1000, Moon dataset, 0.1 noise level, 10000 observations\n",
      "261) svm, gamma = 0.001, Moon dataset, 0.2 noise level, 10000 observations\n",
      "262) svm, gamma = 0.005, Moon dataset, 0.2 noise level, 10000 observations\n",
      "263) svm, gamma = 0.01, Moon dataset, 0.2 noise level, 10000 observations\n",
      "264) svm, gamma = 0.1, Moon dataset, 0.2 noise level, 10000 observations\n",
      "265) svm, gamma = 0.5, Moon dataset, 0.2 noise level, 10000 observations\n",
      "266) svm, gamma = 1, Moon dataset, 0.2 noise level, 10000 observations\n",
      "267) svm, gamma = 5, Moon dataset, 0.2 noise level, 10000 observations\n",
      "268) svm, gamma = 10, Moon dataset, 0.2 noise level, 10000 observations\n",
      "269) svm, gamma = 100, Moon dataset, 0.2 noise level, 10000 observations\n",
      "270) svm, gamma = 1000, Moon dataset, 0.2 noise level, 10000 observations\n",
      "271) svm, gamma = 0.001, Moon dataset, 0.3 noise level, 10000 observations\n",
      "272) svm, gamma = 0.005, Moon dataset, 0.3 noise level, 10000 observations\n",
      "273) svm, gamma = 0.01, Moon dataset, 0.3 noise level, 10000 observations\n",
      "274) svm, gamma = 0.1, Moon dataset, 0.3 noise level, 10000 observations\n",
      "275) svm, gamma = 0.5, Moon dataset, 0.3 noise level, 10000 observations\n",
      "276) svm, gamma = 1, Moon dataset, 0.3 noise level, 10000 observations\n",
      "277) svm, gamma = 5, Moon dataset, 0.3 noise level, 10000 observations\n",
      "278) svm, gamma = 10, Moon dataset, 0.3 noise level, 10000 observations\n",
      "279) svm, gamma = 100, Moon dataset, 0.3 noise level, 10000 observations\n",
      "280) svm, gamma = 1000, Moon dataset, 0.3 noise level, 10000 observations\n",
      "281) svm, gamma = 0.001, Moon dataset, 0.4 noise level, 10000 observations\n",
      "282) svm, gamma = 0.005, Moon dataset, 0.4 noise level, 10000 observations\n",
      "283) svm, gamma = 0.01, Moon dataset, 0.4 noise level, 10000 observations\n",
      "284) svm, gamma = 0.1, Moon dataset, 0.4 noise level, 10000 observations\n",
      "285) svm, gamma = 0.5, Moon dataset, 0.4 noise level, 10000 observations\n",
      "286) svm, gamma = 1, Moon dataset, 0.4 noise level, 10000 observations\n",
      "287) svm, gamma = 5, Moon dataset, 0.4 noise level, 10000 observations\n",
      "288) svm, gamma = 10, Moon dataset, 0.4 noise level, 10000 observations\n",
      "289) svm, gamma = 100, Moon dataset, 0.4 noise level, 10000 observations\n",
      "290) svm, gamma = 1000, Moon dataset, 0.4 noise level, 10000 observations\n",
      "291) svm, gamma = 0.001, Moon dataset, 0.5 noise level, 10000 observations\n",
      "292) svm, gamma = 0.005, Moon dataset, 0.5 noise level, 10000 observations\n",
      "293) svm, gamma = 0.01, Moon dataset, 0.5 noise level, 10000 observations\n",
      "294) svm, gamma = 0.1, Moon dataset, 0.5 noise level, 10000 observations\n",
      "295) svm, gamma = 0.5, Moon dataset, 0.5 noise level, 10000 observations\n",
      "296) svm, gamma = 1, Moon dataset, 0.5 noise level, 10000 observations\n",
      "297) svm, gamma = 5, Moon dataset, 0.5 noise level, 10000 observations\n",
      "298) svm, gamma = 10, Moon dataset, 0.5 noise level, 10000 observations\n",
      "299) svm, gamma = 100, Moon dataset, 0.5 noise level, 10000 observations\n",
      "300) svm, gamma = 1000, Moon dataset, 0.5 noise level, 10000 observations\n",
      "1) logit, C = 0.001, Moon dataset, 0 noise level, 10 observations\n",
      "2) logit, C = 0.01, Moon dataset, 0 noise level, 10 observations\n",
      "3) logit, C = 0.1, Moon dataset, 0 noise level, 10 observations\n",
      "4) logit, C = 1, Moon dataset, 0 noise level, 10 observations\n",
      "5) logit, C = 10, Moon dataset, 0 noise level, 10 observations\n",
      "6) logit, C = 100, Moon dataset, 0 noise level, 10 observations\n",
      "7) logit, C = 1000, Moon dataset, 0 noise level, 10 observations\n",
      "8) logit, C = 0.001, Moon dataset, 0.1 noise level, 10 observations\n",
      "9) logit, C = 0.01, Moon dataset, 0.1 noise level, 10 observations\n",
      "10) logit, C = 0.1, Moon dataset, 0.1 noise level, 10 observations\n",
      "11) logit, C = 1, Moon dataset, 0.1 noise level, 10 observations\n",
      "12) logit, C = 10, Moon dataset, 0.1 noise level, 10 observations\n",
      "13) logit, C = 100, Moon dataset, 0.1 noise level, 10 observations\n",
      "14) logit, C = 1000, Moon dataset, 0.1 noise level, 10 observations\n",
      "15) logit, C = 0.001, Moon dataset, 0.2 noise level, 10 observations\n",
      "16) logit, C = 0.01, Moon dataset, 0.2 noise level, 10 observations\n",
      "17) logit, C = 0.1, Moon dataset, 0.2 noise level, 10 observations\n",
      "18) logit, C = 1, Moon dataset, 0.2 noise level, 10 observations\n",
      "19) logit, C = 10, Moon dataset, 0.2 noise level, 10 observations\n",
      "20) logit, C = 100, Moon dataset, 0.2 noise level, 10 observations\n",
      "21) logit, C = 1000, Moon dataset, 0.2 noise level, 10 observations\n",
      "22) logit, C = 0.001, Moon dataset, 0.3 noise level, 10 observations\n",
      "23) logit, C = 0.01, Moon dataset, 0.3 noise level, 10 observations\n",
      "24) logit, C = 0.1, Moon dataset, 0.3 noise level, 10 observations\n",
      "25) logit, C = 1, Moon dataset, 0.3 noise level, 10 observations\n",
      "26) logit, C = 10, Moon dataset, 0.3 noise level, 10 observations\n",
      "27) logit, C = 100, Moon dataset, 0.3 noise level, 10 observations\n",
      "28) logit, C = 1000, Moon dataset, 0.3 noise level, 10 observations\n",
      "29) logit, C = 0.001, Moon dataset, 0.4 noise level, 10 observations\n",
      "30) logit, C = 0.01, Moon dataset, 0.4 noise level, 10 observations\n",
      "31) logit, C = 0.1, Moon dataset, 0.4 noise level, 10 observations\n",
      "32) logit, C = 1, Moon dataset, 0.4 noise level, 10 observations\n",
      "33) logit, C = 10, Moon dataset, 0.4 noise level, 10 observations\n",
      "34) logit, C = 100, Moon dataset, 0.4 noise level, 10 observations\n",
      "35) logit, C = 1000, Moon dataset, 0.4 noise level, 10 observations\n",
      "36) logit, C = 0.001, Moon dataset, 0.5 noise level, 10 observations\n",
      "37) logit, C = 0.01, Moon dataset, 0.5 noise level, 10 observations\n",
      "38) logit, C = 0.1, Moon dataset, 0.5 noise level, 10 observations\n",
      "39) logit, C = 1, Moon dataset, 0.5 noise level, 10 observations\n",
      "40) logit, C = 10, Moon dataset, 0.5 noise level, 10 observations\n",
      "41) logit, C = 100, Moon dataset, 0.5 noise level, 10 observations\n",
      "42) logit, C = 1000, Moon dataset, 0.5 noise level, 10 observations\n",
      "43) logit, C = 0.001, Moon dataset, 0 noise level, 50 observations\n",
      "44) logit, C = 0.01, Moon dataset, 0 noise level, 50 observations\n",
      "45) logit, C = 0.1, Moon dataset, 0 noise level, 50 observations\n",
      "46) logit, C = 1, Moon dataset, 0 noise level, 50 observations\n",
      "47) logit, C = 10, Moon dataset, 0 noise level, 50 observations\n",
      "48) logit, C = 100, Moon dataset, 0 noise level, 50 observations\n",
      "49) logit, C = 1000, Moon dataset, 0 noise level, 50 observations\n",
      "50) logit, C = 0.001, Moon dataset, 0.1 noise level, 50 observations\n",
      "51) logit, C = 0.01, Moon dataset, 0.1 noise level, 50 observations\n",
      "52) logit, C = 0.1, Moon dataset, 0.1 noise level, 50 observations\n",
      "53) logit, C = 1, Moon dataset, 0.1 noise level, 50 observations\n",
      "54) logit, C = 10, Moon dataset, 0.1 noise level, 50 observations\n",
      "55) logit, C = 100, Moon dataset, 0.1 noise level, 50 observations\n",
      "56) logit, C = 1000, Moon dataset, 0.1 noise level, 50 observations\n",
      "57) logit, C = 0.001, Moon dataset, 0.2 noise level, 50 observations\n",
      "58) logit, C = 0.01, Moon dataset, 0.2 noise level, 50 observations\n",
      "59) logit, C = 0.1, Moon dataset, 0.2 noise level, 50 observations\n",
      "60) logit, C = 1, Moon dataset, 0.2 noise level, 50 observations\n",
      "61) logit, C = 10, Moon dataset, 0.2 noise level, 50 observations\n",
      "62) logit, C = 100, Moon dataset, 0.2 noise level, 50 observations\n",
      "63) logit, C = 1000, Moon dataset, 0.2 noise level, 50 observations\n",
      "64) logit, C = 0.001, Moon dataset, 0.3 noise level, 50 observations\n",
      "65) logit, C = 0.01, Moon dataset, 0.3 noise level, 50 observations\n",
      "66) logit, C = 0.1, Moon dataset, 0.3 noise level, 50 observations\n",
      "67) logit, C = 1, Moon dataset, 0.3 noise level, 50 observations\n",
      "68) logit, C = 10, Moon dataset, 0.3 noise level, 50 observations\n",
      "69) logit, C = 100, Moon dataset, 0.3 noise level, 50 observations\n",
      "70) logit, C = 1000, Moon dataset, 0.3 noise level, 50 observations\n",
      "71) logit, C = 0.001, Moon dataset, 0.4 noise level, 50 observations\n",
      "72) logit, C = 0.01, Moon dataset, 0.4 noise level, 50 observations\n",
      "73) logit, C = 0.1, Moon dataset, 0.4 noise level, 50 observations\n",
      "74) logit, C = 1, Moon dataset, 0.4 noise level, 50 observations\n",
      "75) logit, C = 10, Moon dataset, 0.4 noise level, 50 observations\n",
      "76) logit, C = 100, Moon dataset, 0.4 noise level, 50 observations\n",
      "77) logit, C = 1000, Moon dataset, 0.4 noise level, 50 observations\n",
      "78) logit, C = 0.001, Moon dataset, 0.5 noise level, 50 observations\n",
      "79) logit, C = 0.01, Moon dataset, 0.5 noise level, 50 observations\n",
      "80) logit, C = 0.1, Moon dataset, 0.5 noise level, 50 observations\n",
      "81) logit, C = 1, Moon dataset, 0.5 noise level, 50 observations\n",
      "82) logit, C = 10, Moon dataset, 0.5 noise level, 50 observations\n",
      "83) logit, C = 100, Moon dataset, 0.5 noise level, 50 observations\n",
      "84) logit, C = 1000, Moon dataset, 0.5 noise level, 50 observations\n",
      "85) logit, C = 0.001, Moon dataset, 0 noise level, 100 observations\n",
      "86) logit, C = 0.01, Moon dataset, 0 noise level, 100 observations\n",
      "87) logit, C = 0.1, Moon dataset, 0 noise level, 100 observations\n",
      "88) logit, C = 1, Moon dataset, 0 noise level, 100 observations\n",
      "89) logit, C = 10, Moon dataset, 0 noise level, 100 observations\n",
      "90) logit, C = 100, Moon dataset, 0 noise level, 100 observations\n",
      "91) logit, C = 1000, Moon dataset, 0 noise level, 100 observations\n",
      "92) logit, C = 0.001, Moon dataset, 0.1 noise level, 100 observations\n",
      "93) logit, C = 0.01, Moon dataset, 0.1 noise level, 100 observations\n",
      "94) logit, C = 0.1, Moon dataset, 0.1 noise level, 100 observations\n",
      "95) logit, C = 1, Moon dataset, 0.1 noise level, 100 observations\n",
      "96) logit, C = 10, Moon dataset, 0.1 noise level, 100 observations\n",
      "97) logit, C = 100, Moon dataset, 0.1 noise level, 100 observations\n",
      "98) logit, C = 1000, Moon dataset, 0.1 noise level, 100 observations\n",
      "99) logit, C = 0.001, Moon dataset, 0.2 noise level, 100 observations\n",
      "100) logit, C = 0.01, Moon dataset, 0.2 noise level, 100 observations\n",
      "101) logit, C = 0.1, Moon dataset, 0.2 noise level, 100 observations\n",
      "102) logit, C = 1, Moon dataset, 0.2 noise level, 100 observations\n",
      "103) logit, C = 10, Moon dataset, 0.2 noise level, 100 observations\n",
      "104) logit, C = 100, Moon dataset, 0.2 noise level, 100 observations\n",
      "105) logit, C = 1000, Moon dataset, 0.2 noise level, 100 observations\n",
      "106) logit, C = 0.001, Moon dataset, 0.3 noise level, 100 observations\n",
      "107) logit, C = 0.01, Moon dataset, 0.3 noise level, 100 observations\n",
      "108) logit, C = 0.1, Moon dataset, 0.3 noise level, 100 observations\n",
      "109) logit, C = 1, Moon dataset, 0.3 noise level, 100 observations\n",
      "110) logit, C = 10, Moon dataset, 0.3 noise level, 100 observations\n",
      "111) logit, C = 100, Moon dataset, 0.3 noise level, 100 observations\n",
      "112) logit, C = 1000, Moon dataset, 0.3 noise level, 100 observations\n",
      "113) logit, C = 0.001, Moon dataset, 0.4 noise level, 100 observations\n",
      "114) logit, C = 0.01, Moon dataset, 0.4 noise level, 100 observations\n",
      "115) logit, C = 0.1, Moon dataset, 0.4 noise level, 100 observations\n",
      "116) logit, C = 1, Moon dataset, 0.4 noise level, 100 observations\n",
      "117) logit, C = 10, Moon dataset, 0.4 noise level, 100 observations\n",
      "118) logit, C = 100, Moon dataset, 0.4 noise level, 100 observations\n",
      "119) logit, C = 1000, Moon dataset, 0.4 noise level, 100 observations\n",
      "120) logit, C = 0.001, Moon dataset, 0.5 noise level, 100 observations\n",
      "121) logit, C = 0.01, Moon dataset, 0.5 noise level, 100 observations\n",
      "122) logit, C = 0.1, Moon dataset, 0.5 noise level, 100 observations\n",
      "123) logit, C = 1, Moon dataset, 0.5 noise level, 100 observations\n",
      "124) logit, C = 10, Moon dataset, 0.5 noise level, 100 observations\n",
      "125) logit, C = 100, Moon dataset, 0.5 noise level, 100 observations\n",
      "126) logit, C = 1000, Moon dataset, 0.5 noise level, 100 observations\n",
      "127) logit, C = 0.001, Moon dataset, 0 noise level, 1000 observations\n",
      "128) logit, C = 0.01, Moon dataset, 0 noise level, 1000 observations\n",
      "129) logit, C = 0.1, Moon dataset, 0 noise level, 1000 observations\n",
      "130) logit, C = 1, Moon dataset, 0 noise level, 1000 observations\n",
      "131) logit, C = 10, Moon dataset, 0 noise level, 1000 observations\n",
      "132) logit, C = 100, Moon dataset, 0 noise level, 1000 observations\n",
      "133) logit, C = 1000, Moon dataset, 0 noise level, 1000 observations\n",
      "134) logit, C = 0.001, Moon dataset, 0.1 noise level, 1000 observations\n",
      "135) logit, C = 0.01, Moon dataset, 0.1 noise level, 1000 observations\n",
      "136) logit, C = 0.1, Moon dataset, 0.1 noise level, 1000 observations\n",
      "137) logit, C = 1, Moon dataset, 0.1 noise level, 1000 observations\n",
      "138) logit, C = 10, Moon dataset, 0.1 noise level, 1000 observations\n",
      "139) logit, C = 100, Moon dataset, 0.1 noise level, 1000 observations\n",
      "140) logit, C = 1000, Moon dataset, 0.1 noise level, 1000 observations\n",
      "141) logit, C = 0.001, Moon dataset, 0.2 noise level, 1000 observations\n",
      "142) logit, C = 0.01, Moon dataset, 0.2 noise level, 1000 observations\n",
      "143) logit, C = 0.1, Moon dataset, 0.2 noise level, 1000 observations\n",
      "144) logit, C = 1, Moon dataset, 0.2 noise level, 1000 observations\n",
      "145) logit, C = 10, Moon dataset, 0.2 noise level, 1000 observations\n",
      "146) logit, C = 100, Moon dataset, 0.2 noise level, 1000 observations\n",
      "147) logit, C = 1000, Moon dataset, 0.2 noise level, 1000 observations\n",
      "148) logit, C = 0.001, Moon dataset, 0.3 noise level, 1000 observations\n",
      "149) logit, C = 0.01, Moon dataset, 0.3 noise level, 1000 observations\n",
      "150) logit, C = 0.1, Moon dataset, 0.3 noise level, 1000 observations\n",
      "151) logit, C = 1, Moon dataset, 0.3 noise level, 1000 observations\n",
      "152) logit, C = 10, Moon dataset, 0.3 noise level, 1000 observations\n",
      "153) logit, C = 100, Moon dataset, 0.3 noise level, 1000 observations\n",
      "154) logit, C = 1000, Moon dataset, 0.3 noise level, 1000 observations\n",
      "155) logit, C = 0.001, Moon dataset, 0.4 noise level, 1000 observations\n",
      "156) logit, C = 0.01, Moon dataset, 0.4 noise level, 1000 observations\n",
      "157) logit, C = 0.1, Moon dataset, 0.4 noise level, 1000 observations\n",
      "158) logit, C = 1, Moon dataset, 0.4 noise level, 1000 observations\n",
      "159) logit, C = 10, Moon dataset, 0.4 noise level, 1000 observations\n",
      "160) logit, C = 100, Moon dataset, 0.4 noise level, 1000 observations\n",
      "161) logit, C = 1000, Moon dataset, 0.4 noise level, 1000 observations\n",
      "162) logit, C = 0.001, Moon dataset, 0.5 noise level, 1000 observations\n",
      "163) logit, C = 0.01, Moon dataset, 0.5 noise level, 1000 observations\n",
      "164) logit, C = 0.1, Moon dataset, 0.5 noise level, 1000 observations\n",
      "165) logit, C = 1, Moon dataset, 0.5 noise level, 1000 observations\n",
      "166) logit, C = 10, Moon dataset, 0.5 noise level, 1000 observations\n",
      "167) logit, C = 100, Moon dataset, 0.5 noise level, 1000 observations\n",
      "168) logit, C = 1000, Moon dataset, 0.5 noise level, 1000 observations\n",
      "169) logit, C = 0.001, Moon dataset, 0 noise level, 10000 observations\n",
      "170) logit, C = 0.01, Moon dataset, 0 noise level, 10000 observations\n",
      "171) logit, C = 0.1, Moon dataset, 0 noise level, 10000 observations\n",
      "172) logit, C = 1, Moon dataset, 0 noise level, 10000 observations\n",
      "173) logit, C = 10, Moon dataset, 0 noise level, 10000 observations\n",
      "174) logit, C = 100, Moon dataset, 0 noise level, 10000 observations\n",
      "175) logit, C = 1000, Moon dataset, 0 noise level, 10000 observations\n",
      "176) logit, C = 0.001, Moon dataset, 0.1 noise level, 10000 observations\n",
      "177) logit, C = 0.01, Moon dataset, 0.1 noise level, 10000 observations\n",
      "178) logit, C = 0.1, Moon dataset, 0.1 noise level, 10000 observations\n",
      "179) logit, C = 1, Moon dataset, 0.1 noise level, 10000 observations\n",
      "180) logit, C = 10, Moon dataset, 0.1 noise level, 10000 observations\n",
      "181) logit, C = 100, Moon dataset, 0.1 noise level, 10000 observations\n",
      "182) logit, C = 1000, Moon dataset, 0.1 noise level, 10000 observations\n",
      "183) logit, C = 0.001, Moon dataset, 0.2 noise level, 10000 observations\n",
      "184) logit, C = 0.01, Moon dataset, 0.2 noise level, 10000 observations\n",
      "185) logit, C = 0.1, Moon dataset, 0.2 noise level, 10000 observations\n",
      "186) logit, C = 1, Moon dataset, 0.2 noise level, 10000 observations\n",
      "187) logit, C = 10, Moon dataset, 0.2 noise level, 10000 observations\n",
      "188) logit, C = 100, Moon dataset, 0.2 noise level, 10000 observations\n",
      "189) logit, C = 1000, Moon dataset, 0.2 noise level, 10000 observations\n",
      "190) logit, C = 0.001, Moon dataset, 0.3 noise level, 10000 observations\n",
      "191) logit, C = 0.01, Moon dataset, 0.3 noise level, 10000 observations\n",
      "192) logit, C = 0.1, Moon dataset, 0.3 noise level, 10000 observations\n",
      "193) logit, C = 1, Moon dataset, 0.3 noise level, 10000 observations\n",
      "194) logit, C = 10, Moon dataset, 0.3 noise level, 10000 observations\n",
      "195) logit, C = 100, Moon dataset, 0.3 noise level, 10000 observations\n",
      "196) logit, C = 1000, Moon dataset, 0.3 noise level, 10000 observations\n",
      "197) logit, C = 0.001, Moon dataset, 0.4 noise level, 10000 observations\n",
      "198) logit, C = 0.01, Moon dataset, 0.4 noise level, 10000 observations\n",
      "199) logit, C = 0.1, Moon dataset, 0.4 noise level, 10000 observations\n",
      "200) logit, C = 1, Moon dataset, 0.4 noise level, 10000 observations\n",
      "201) logit, C = 10, Moon dataset, 0.4 noise level, 10000 observations\n",
      "202) logit, C = 100, Moon dataset, 0.4 noise level, 10000 observations\n",
      "203) logit, C = 1000, Moon dataset, 0.4 noise level, 10000 observations\n",
      "204) logit, C = 0.001, Moon dataset, 0.5 noise level, 10000 observations\n",
      "205) logit, C = 0.01, Moon dataset, 0.5 noise level, 10000 observations\n",
      "206) logit, C = 0.1, Moon dataset, 0.5 noise level, 10000 observations\n",
      "207) logit, C = 1, Moon dataset, 0.5 noise level, 10000 observations\n",
      "208) logit, C = 10, Moon dataset, 0.5 noise level, 10000 observations\n",
      "209) logit, C = 100, Moon dataset, 0.5 noise level, 10000 observations\n",
      "210) logit, C = 1000, Moon dataset, 0.5 noise level, 10000 observations\n",
      "301) svm, gamma = 0.001, Circle dataset, 0 noise level, 10 observations\n",
      "302) svm, gamma = 0.005, Circle dataset, 0 noise level, 10 observations\n",
      "303) svm, gamma = 0.01, Circle dataset, 0 noise level, 10 observations\n",
      "304) svm, gamma = 0.1, Circle dataset, 0 noise level, 10 observations\n",
      "305) svm, gamma = 0.5, Circle dataset, 0 noise level, 10 observations\n",
      "306) svm, gamma = 1, Circle dataset, 0 noise level, 10 observations\n",
      "307) svm, gamma = 5, Circle dataset, 0 noise level, 10 observations\n",
      "308) svm, gamma = 10, Circle dataset, 0 noise level, 10 observations\n",
      "309) svm, gamma = 100, Circle dataset, 0 noise level, 10 observations\n",
      "310) svm, gamma = 1000, Circle dataset, 0 noise level, 10 observations\n",
      "311) svm, gamma = 0.001, Circle dataset, 0.1 noise level, 10 observations\n",
      "312) svm, gamma = 0.005, Circle dataset, 0.1 noise level, 10 observations\n",
      "313) svm, gamma = 0.01, Circle dataset, 0.1 noise level, 10 observations\n",
      "314) svm, gamma = 0.1, Circle dataset, 0.1 noise level, 10 observations\n",
      "315) svm, gamma = 0.5, Circle dataset, 0.1 noise level, 10 observations\n",
      "316) svm, gamma = 1, Circle dataset, 0.1 noise level, 10 observations\n",
      "317) svm, gamma = 5, Circle dataset, 0.1 noise level, 10 observations\n",
      "318) svm, gamma = 10, Circle dataset, 0.1 noise level, 10 observations\n",
      "319) svm, gamma = 100, Circle dataset, 0.1 noise level, 10 observations\n",
      "320) svm, gamma = 1000, Circle dataset, 0.1 noise level, 10 observations\n",
      "321) svm, gamma = 0.001, Circle dataset, 0.2 noise level, 10 observations\n",
      "322) svm, gamma = 0.005, Circle dataset, 0.2 noise level, 10 observations\n",
      "323) svm, gamma = 0.01, Circle dataset, 0.2 noise level, 10 observations\n",
      "324) svm, gamma = 0.1, Circle dataset, 0.2 noise level, 10 observations\n",
      "325) svm, gamma = 0.5, Circle dataset, 0.2 noise level, 10 observations\n",
      "326) svm, gamma = 1, Circle dataset, 0.2 noise level, 10 observations\n",
      "327) svm, gamma = 5, Circle dataset, 0.2 noise level, 10 observations\n",
      "328) svm, gamma = 10, Circle dataset, 0.2 noise level, 10 observations\n",
      "329) svm, gamma = 100, Circle dataset, 0.2 noise level, 10 observations\n",
      "330) svm, gamma = 1000, Circle dataset, 0.2 noise level, 10 observations\n",
      "331) svm, gamma = 0.001, Circle dataset, 0.3 noise level, 10 observations\n",
      "332) svm, gamma = 0.005, Circle dataset, 0.3 noise level, 10 observations\n",
      "333) svm, gamma = 0.01, Circle dataset, 0.3 noise level, 10 observations\n",
      "334) svm, gamma = 0.1, Circle dataset, 0.3 noise level, 10 observations\n",
      "335) svm, gamma = 0.5, Circle dataset, 0.3 noise level, 10 observations\n",
      "336) svm, gamma = 1, Circle dataset, 0.3 noise level, 10 observations\n",
      "337) svm, gamma = 5, Circle dataset, 0.3 noise level, 10 observations\n",
      "338) svm, gamma = 10, Circle dataset, 0.3 noise level, 10 observations\n",
      "339) svm, gamma = 100, Circle dataset, 0.3 noise level, 10 observations\n",
      "340) svm, gamma = 1000, Circle dataset, 0.3 noise level, 10 observations\n",
      "341) svm, gamma = 0.001, Circle dataset, 0.4 noise level, 10 observations\n",
      "342) svm, gamma = 0.005, Circle dataset, 0.4 noise level, 10 observations\n",
      "343) svm, gamma = 0.01, Circle dataset, 0.4 noise level, 10 observations\n",
      "344) svm, gamma = 0.1, Circle dataset, 0.4 noise level, 10 observations\n",
      "345) svm, gamma = 0.5, Circle dataset, 0.4 noise level, 10 observations\n",
      "346) svm, gamma = 1, Circle dataset, 0.4 noise level, 10 observations\n",
      "347) svm, gamma = 5, Circle dataset, 0.4 noise level, 10 observations\n",
      "348) svm, gamma = 10, Circle dataset, 0.4 noise level, 10 observations\n",
      "349) svm, gamma = 100, Circle dataset, 0.4 noise level, 10 observations\n",
      "350) svm, gamma = 1000, Circle dataset, 0.4 noise level, 10 observations\n",
      "351) svm, gamma = 0.001, Circle dataset, 0.5 noise level, 10 observations\n",
      "352) svm, gamma = 0.005, Circle dataset, 0.5 noise level, 10 observations\n",
      "353) svm, gamma = 0.01, Circle dataset, 0.5 noise level, 10 observations\n",
      "354) svm, gamma = 0.1, Circle dataset, 0.5 noise level, 10 observations\n",
      "355) svm, gamma = 0.5, Circle dataset, 0.5 noise level, 10 observations\n",
      "356) svm, gamma = 1, Circle dataset, 0.5 noise level, 10 observations\n",
      "357) svm, gamma = 5, Circle dataset, 0.5 noise level, 10 observations\n",
      "358) svm, gamma = 10, Circle dataset, 0.5 noise level, 10 observations\n",
      "359) svm, gamma = 100, Circle dataset, 0.5 noise level, 10 observations\n",
      "360) svm, gamma = 1000, Circle dataset, 0.5 noise level, 10 observations\n",
      "361) svm, gamma = 0.001, Circle dataset, 0 noise level, 50 observations\n",
      "362) svm, gamma = 0.005, Circle dataset, 0 noise level, 50 observations\n",
      "363) svm, gamma = 0.01, Circle dataset, 0 noise level, 50 observations\n",
      "364) svm, gamma = 0.1, Circle dataset, 0 noise level, 50 observations\n",
      "365) svm, gamma = 0.5, Circle dataset, 0 noise level, 50 observations\n",
      "366) svm, gamma = 1, Circle dataset, 0 noise level, 50 observations\n",
      "367) svm, gamma = 5, Circle dataset, 0 noise level, 50 observations\n",
      "368) svm, gamma = 10, Circle dataset, 0 noise level, 50 observations\n",
      "369) svm, gamma = 100, Circle dataset, 0 noise level, 50 observations\n",
      "370) svm, gamma = 1000, Circle dataset, 0 noise level, 50 observations\n",
      "371) svm, gamma = 0.001, Circle dataset, 0.1 noise level, 50 observations\n",
      "372) svm, gamma = 0.005, Circle dataset, 0.1 noise level, 50 observations\n",
      "373) svm, gamma = 0.01, Circle dataset, 0.1 noise level, 50 observations\n",
      "374) svm, gamma = 0.1, Circle dataset, 0.1 noise level, 50 observations\n",
      "375) svm, gamma = 0.5, Circle dataset, 0.1 noise level, 50 observations\n",
      "376) svm, gamma = 1, Circle dataset, 0.1 noise level, 50 observations\n",
      "377) svm, gamma = 5, Circle dataset, 0.1 noise level, 50 observations\n",
      "378) svm, gamma = 10, Circle dataset, 0.1 noise level, 50 observations\n",
      "379) svm, gamma = 100, Circle dataset, 0.1 noise level, 50 observations\n",
      "380) svm, gamma = 1000, Circle dataset, 0.1 noise level, 50 observations\n",
      "381) svm, gamma = 0.001, Circle dataset, 0.2 noise level, 50 observations\n",
      "382) svm, gamma = 0.005, Circle dataset, 0.2 noise level, 50 observations\n",
      "383) svm, gamma = 0.01, Circle dataset, 0.2 noise level, 50 observations\n",
      "384) svm, gamma = 0.1, Circle dataset, 0.2 noise level, 50 observations\n",
      "385) svm, gamma = 0.5, Circle dataset, 0.2 noise level, 50 observations\n",
      "386) svm, gamma = 1, Circle dataset, 0.2 noise level, 50 observations\n",
      "387) svm, gamma = 5, Circle dataset, 0.2 noise level, 50 observations\n",
      "388) svm, gamma = 10, Circle dataset, 0.2 noise level, 50 observations\n",
      "389) svm, gamma = 100, Circle dataset, 0.2 noise level, 50 observations\n",
      "390) svm, gamma = 1000, Circle dataset, 0.2 noise level, 50 observations\n",
      "391) svm, gamma = 0.001, Circle dataset, 0.3 noise level, 50 observations\n",
      "392) svm, gamma = 0.005, Circle dataset, 0.3 noise level, 50 observations\n",
      "393) svm, gamma = 0.01, Circle dataset, 0.3 noise level, 50 observations\n",
      "394) svm, gamma = 0.1, Circle dataset, 0.3 noise level, 50 observations\n",
      "395) svm, gamma = 0.5, Circle dataset, 0.3 noise level, 50 observations\n",
      "396) svm, gamma = 1, Circle dataset, 0.3 noise level, 50 observations\n",
      "397) svm, gamma = 5, Circle dataset, 0.3 noise level, 50 observations\n",
      "398) svm, gamma = 10, Circle dataset, 0.3 noise level, 50 observations\n",
      "399) svm, gamma = 100, Circle dataset, 0.3 noise level, 50 observations\n",
      "400) svm, gamma = 1000, Circle dataset, 0.3 noise level, 50 observations\n",
      "401) svm, gamma = 0.001, Circle dataset, 0.4 noise level, 50 observations\n",
      "402) svm, gamma = 0.005, Circle dataset, 0.4 noise level, 50 observations\n",
      "403) svm, gamma = 0.01, Circle dataset, 0.4 noise level, 50 observations\n",
      "404) svm, gamma = 0.1, Circle dataset, 0.4 noise level, 50 observations\n",
      "405) svm, gamma = 0.5, Circle dataset, 0.4 noise level, 50 observations\n",
      "406) svm, gamma = 1, Circle dataset, 0.4 noise level, 50 observations\n",
      "407) svm, gamma = 5, Circle dataset, 0.4 noise level, 50 observations\n",
      "408) svm, gamma = 10, Circle dataset, 0.4 noise level, 50 observations\n",
      "409) svm, gamma = 100, Circle dataset, 0.4 noise level, 50 observations\n",
      "410) svm, gamma = 1000, Circle dataset, 0.4 noise level, 50 observations\n",
      "411) svm, gamma = 0.001, Circle dataset, 0.5 noise level, 50 observations\n",
      "412) svm, gamma = 0.005, Circle dataset, 0.5 noise level, 50 observations\n",
      "413) svm, gamma = 0.01, Circle dataset, 0.5 noise level, 50 observations\n",
      "414) svm, gamma = 0.1, Circle dataset, 0.5 noise level, 50 observations\n",
      "415) svm, gamma = 0.5, Circle dataset, 0.5 noise level, 50 observations\n",
      "416) svm, gamma = 1, Circle dataset, 0.5 noise level, 50 observations\n",
      "417) svm, gamma = 5, Circle dataset, 0.5 noise level, 50 observations\n",
      "418) svm, gamma = 10, Circle dataset, 0.5 noise level, 50 observations\n",
      "419) svm, gamma = 100, Circle dataset, 0.5 noise level, 50 observations\n",
      "420) svm, gamma = 1000, Circle dataset, 0.5 noise level, 50 observations\n",
      "421) svm, gamma = 0.001, Circle dataset, 0 noise level, 100 observations\n",
      "422) svm, gamma = 0.005, Circle dataset, 0 noise level, 100 observations\n",
      "423) svm, gamma = 0.01, Circle dataset, 0 noise level, 100 observations\n",
      "424) svm, gamma = 0.1, Circle dataset, 0 noise level, 100 observations\n",
      "425) svm, gamma = 0.5, Circle dataset, 0 noise level, 100 observations\n",
      "426) svm, gamma = 1, Circle dataset, 0 noise level, 100 observations\n",
      "427) svm, gamma = 5, Circle dataset, 0 noise level, 100 observations\n",
      "428) svm, gamma = 10, Circle dataset, 0 noise level, 100 observations\n",
      "429) svm, gamma = 100, Circle dataset, 0 noise level, 100 observations\n",
      "430) svm, gamma = 1000, Circle dataset, 0 noise level, 100 observations\n",
      "431) svm, gamma = 0.001, Circle dataset, 0.1 noise level, 100 observations\n",
      "432) svm, gamma = 0.005, Circle dataset, 0.1 noise level, 100 observations\n",
      "433) svm, gamma = 0.01, Circle dataset, 0.1 noise level, 100 observations\n",
      "434) svm, gamma = 0.1, Circle dataset, 0.1 noise level, 100 observations\n",
      "435) svm, gamma = 0.5, Circle dataset, 0.1 noise level, 100 observations\n",
      "436) svm, gamma = 1, Circle dataset, 0.1 noise level, 100 observations\n",
      "437) svm, gamma = 5, Circle dataset, 0.1 noise level, 100 observations\n",
      "438) svm, gamma = 10, Circle dataset, 0.1 noise level, 100 observations\n",
      "439) svm, gamma = 100, Circle dataset, 0.1 noise level, 100 observations\n",
      "440) svm, gamma = 1000, Circle dataset, 0.1 noise level, 100 observations\n",
      "441) svm, gamma = 0.001, Circle dataset, 0.2 noise level, 100 observations\n",
      "442) svm, gamma = 0.005, Circle dataset, 0.2 noise level, 100 observations\n",
      "443) svm, gamma = 0.01, Circle dataset, 0.2 noise level, 100 observations\n",
      "444) svm, gamma = 0.1, Circle dataset, 0.2 noise level, 100 observations\n",
      "445) svm, gamma = 0.5, Circle dataset, 0.2 noise level, 100 observations\n",
      "446) svm, gamma = 1, Circle dataset, 0.2 noise level, 100 observations\n",
      "447) svm, gamma = 5, Circle dataset, 0.2 noise level, 100 observations\n",
      "448) svm, gamma = 10, Circle dataset, 0.2 noise level, 100 observations\n",
      "449) svm, gamma = 100, Circle dataset, 0.2 noise level, 100 observations\n",
      "450) svm, gamma = 1000, Circle dataset, 0.2 noise level, 100 observations\n",
      "451) svm, gamma = 0.001, Circle dataset, 0.3 noise level, 100 observations\n",
      "452) svm, gamma = 0.005, Circle dataset, 0.3 noise level, 100 observations\n",
      "453) svm, gamma = 0.01, Circle dataset, 0.3 noise level, 100 observations\n",
      "454) svm, gamma = 0.1, Circle dataset, 0.3 noise level, 100 observations\n",
      "455) svm, gamma = 0.5, Circle dataset, 0.3 noise level, 100 observations\n",
      "456) svm, gamma = 1, Circle dataset, 0.3 noise level, 100 observations\n",
      "457) svm, gamma = 5, Circle dataset, 0.3 noise level, 100 observations\n",
      "458) svm, gamma = 10, Circle dataset, 0.3 noise level, 100 observations\n",
      "459) svm, gamma = 100, Circle dataset, 0.3 noise level, 100 observations\n",
      "460) svm, gamma = 1000, Circle dataset, 0.3 noise level, 100 observations\n",
      "461) svm, gamma = 0.001, Circle dataset, 0.4 noise level, 100 observations\n",
      "462) svm, gamma = 0.005, Circle dataset, 0.4 noise level, 100 observations\n",
      "463) svm, gamma = 0.01, Circle dataset, 0.4 noise level, 100 observations\n",
      "464) svm, gamma = 0.1, Circle dataset, 0.4 noise level, 100 observations\n",
      "465) svm, gamma = 0.5, Circle dataset, 0.4 noise level, 100 observations\n",
      "466) svm, gamma = 1, Circle dataset, 0.4 noise level, 100 observations\n",
      "467) svm, gamma = 5, Circle dataset, 0.4 noise level, 100 observations\n",
      "468) svm, gamma = 10, Circle dataset, 0.4 noise level, 100 observations\n",
      "469) svm, gamma = 100, Circle dataset, 0.4 noise level, 100 observations\n",
      "470) svm, gamma = 1000, Circle dataset, 0.4 noise level, 100 observations\n",
      "471) svm, gamma = 0.001, Circle dataset, 0.5 noise level, 100 observations\n",
      "472) svm, gamma = 0.005, Circle dataset, 0.5 noise level, 100 observations\n",
      "473) svm, gamma = 0.01, Circle dataset, 0.5 noise level, 100 observations\n",
      "474) svm, gamma = 0.1, Circle dataset, 0.5 noise level, 100 observations\n",
      "475) svm, gamma = 0.5, Circle dataset, 0.5 noise level, 100 observations\n",
      "476) svm, gamma = 1, Circle dataset, 0.5 noise level, 100 observations\n",
      "477) svm, gamma = 5, Circle dataset, 0.5 noise level, 100 observations\n",
      "478) svm, gamma = 10, Circle dataset, 0.5 noise level, 100 observations\n",
      "479) svm, gamma = 100, Circle dataset, 0.5 noise level, 100 observations\n",
      "480) svm, gamma = 1000, Circle dataset, 0.5 noise level, 100 observations\n",
      "481) svm, gamma = 0.001, Circle dataset, 0 noise level, 1000 observations\n",
      "482) svm, gamma = 0.005, Circle dataset, 0 noise level, 1000 observations\n",
      "483) svm, gamma = 0.01, Circle dataset, 0 noise level, 1000 observations\n",
      "484) svm, gamma = 0.1, Circle dataset, 0 noise level, 1000 observations\n",
      "485) svm, gamma = 0.5, Circle dataset, 0 noise level, 1000 observations\n",
      "486) svm, gamma = 1, Circle dataset, 0 noise level, 1000 observations\n",
      "487) svm, gamma = 5, Circle dataset, 0 noise level, 1000 observations\n",
      "488) svm, gamma = 10, Circle dataset, 0 noise level, 1000 observations\n",
      "489) svm, gamma = 100, Circle dataset, 0 noise level, 1000 observations\n",
      "490) svm, gamma = 1000, Circle dataset, 0 noise level, 1000 observations\n",
      "491) svm, gamma = 0.001, Circle dataset, 0.1 noise level, 1000 observations\n",
      "492) svm, gamma = 0.005, Circle dataset, 0.1 noise level, 1000 observations\n",
      "493) svm, gamma = 0.01, Circle dataset, 0.1 noise level, 1000 observations\n",
      "494) svm, gamma = 0.1, Circle dataset, 0.1 noise level, 1000 observations\n",
      "495) svm, gamma = 0.5, Circle dataset, 0.1 noise level, 1000 observations\n",
      "496) svm, gamma = 1, Circle dataset, 0.1 noise level, 1000 observations\n",
      "497) svm, gamma = 5, Circle dataset, 0.1 noise level, 1000 observations\n",
      "498) svm, gamma = 10, Circle dataset, 0.1 noise level, 1000 observations\n",
      "499) svm, gamma = 100, Circle dataset, 0.1 noise level, 1000 observations\n",
      "500) svm, gamma = 1000, Circle dataset, 0.1 noise level, 1000 observations\n",
      "501) svm, gamma = 0.001, Circle dataset, 0.2 noise level, 1000 observations\n",
      "502) svm, gamma = 0.005, Circle dataset, 0.2 noise level, 1000 observations\n",
      "503) svm, gamma = 0.01, Circle dataset, 0.2 noise level, 1000 observations\n",
      "504) svm, gamma = 0.1, Circle dataset, 0.2 noise level, 1000 observations\n",
      "505) svm, gamma = 0.5, Circle dataset, 0.2 noise level, 1000 observations\n",
      "506) svm, gamma = 1, Circle dataset, 0.2 noise level, 1000 observations\n",
      "507) svm, gamma = 5, Circle dataset, 0.2 noise level, 1000 observations\n",
      "508) svm, gamma = 10, Circle dataset, 0.2 noise level, 1000 observations\n",
      "509) svm, gamma = 100, Circle dataset, 0.2 noise level, 1000 observations\n",
      "510) svm, gamma = 1000, Circle dataset, 0.2 noise level, 1000 observations\n",
      "511) svm, gamma = 0.001, Circle dataset, 0.3 noise level, 1000 observations\n",
      "512) svm, gamma = 0.005, Circle dataset, 0.3 noise level, 1000 observations\n",
      "513) svm, gamma = 0.01, Circle dataset, 0.3 noise level, 1000 observations\n",
      "514) svm, gamma = 0.1, Circle dataset, 0.3 noise level, 1000 observations\n",
      "515) svm, gamma = 0.5, Circle dataset, 0.3 noise level, 1000 observations\n",
      "516) svm, gamma = 1, Circle dataset, 0.3 noise level, 1000 observations\n",
      "517) svm, gamma = 5, Circle dataset, 0.3 noise level, 1000 observations\n",
      "518) svm, gamma = 10, Circle dataset, 0.3 noise level, 1000 observations\n",
      "519) svm, gamma = 100, Circle dataset, 0.3 noise level, 1000 observations\n",
      "520) svm, gamma = 1000, Circle dataset, 0.3 noise level, 1000 observations\n",
      "521) svm, gamma = 0.001, Circle dataset, 0.4 noise level, 1000 observations\n",
      "522) svm, gamma = 0.005, Circle dataset, 0.4 noise level, 1000 observations\n",
      "523) svm, gamma = 0.01, Circle dataset, 0.4 noise level, 1000 observations\n",
      "524) svm, gamma = 0.1, Circle dataset, 0.4 noise level, 1000 observations\n",
      "525) svm, gamma = 0.5, Circle dataset, 0.4 noise level, 1000 observations\n",
      "526) svm, gamma = 1, Circle dataset, 0.4 noise level, 1000 observations\n",
      "527) svm, gamma = 5, Circle dataset, 0.4 noise level, 1000 observations\n",
      "528) svm, gamma = 10, Circle dataset, 0.4 noise level, 1000 observations\n",
      "529) svm, gamma = 100, Circle dataset, 0.4 noise level, 1000 observations\n",
      "530) svm, gamma = 1000, Circle dataset, 0.4 noise level, 1000 observations\n",
      "531) svm, gamma = 0.001, Circle dataset, 0.5 noise level, 1000 observations\n",
      "532) svm, gamma = 0.005, Circle dataset, 0.5 noise level, 1000 observations\n",
      "533) svm, gamma = 0.01, Circle dataset, 0.5 noise level, 1000 observations\n",
      "534) svm, gamma = 0.1, Circle dataset, 0.5 noise level, 1000 observations\n",
      "535) svm, gamma = 0.5, Circle dataset, 0.5 noise level, 1000 observations\n",
      "536) svm, gamma = 1, Circle dataset, 0.5 noise level, 1000 observations\n",
      "537) svm, gamma = 5, Circle dataset, 0.5 noise level, 1000 observations\n",
      "538) svm, gamma = 10, Circle dataset, 0.5 noise level, 1000 observations\n",
      "539) svm, gamma = 100, Circle dataset, 0.5 noise level, 1000 observations\n",
      "540) svm, gamma = 1000, Circle dataset, 0.5 noise level, 1000 observations\n",
      "541) svm, gamma = 0.001, Circle dataset, 0 noise level, 10000 observations\n",
      "542) svm, gamma = 0.005, Circle dataset, 0 noise level, 10000 observations\n",
      "543) svm, gamma = 0.01, Circle dataset, 0 noise level, 10000 observations\n",
      "544) svm, gamma = 0.1, Circle dataset, 0 noise level, 10000 observations\n",
      "545) svm, gamma = 0.5, Circle dataset, 0 noise level, 10000 observations\n",
      "546) svm, gamma = 1, Circle dataset, 0 noise level, 10000 observations\n",
      "547) svm, gamma = 5, Circle dataset, 0 noise level, 10000 observations\n",
      "548) svm, gamma = 10, Circle dataset, 0 noise level, 10000 observations\n",
      "549) svm, gamma = 100, Circle dataset, 0 noise level, 10000 observations\n",
      "550) svm, gamma = 1000, Circle dataset, 0 noise level, 10000 observations\n",
      "551) svm, gamma = 0.001, Circle dataset, 0.1 noise level, 10000 observations\n",
      "552) svm, gamma = 0.005, Circle dataset, 0.1 noise level, 10000 observations\n",
      "553) svm, gamma = 0.01, Circle dataset, 0.1 noise level, 10000 observations\n",
      "554) svm, gamma = 0.1, Circle dataset, 0.1 noise level, 10000 observations\n",
      "555) svm, gamma = 0.5, Circle dataset, 0.1 noise level, 10000 observations\n",
      "556) svm, gamma = 1, Circle dataset, 0.1 noise level, 10000 observations\n",
      "557) svm, gamma = 5, Circle dataset, 0.1 noise level, 10000 observations\n",
      "558) svm, gamma = 10, Circle dataset, 0.1 noise level, 10000 observations\n",
      "559) svm, gamma = 100, Circle dataset, 0.1 noise level, 10000 observations\n",
      "560) svm, gamma = 1000, Circle dataset, 0.1 noise level, 10000 observations\n",
      "561) svm, gamma = 0.001, Circle dataset, 0.2 noise level, 10000 observations\n",
      "562) svm, gamma = 0.005, Circle dataset, 0.2 noise level, 10000 observations\n",
      "563) svm, gamma = 0.01, Circle dataset, 0.2 noise level, 10000 observations\n",
      "564) svm, gamma = 0.1, Circle dataset, 0.2 noise level, 10000 observations\n",
      "565) svm, gamma = 0.5, Circle dataset, 0.2 noise level, 10000 observations\n",
      "566) svm, gamma = 1, Circle dataset, 0.2 noise level, 10000 observations\n",
      "567) svm, gamma = 5, Circle dataset, 0.2 noise level, 10000 observations\n",
      "568) svm, gamma = 10, Circle dataset, 0.2 noise level, 10000 observations\n",
      "569) svm, gamma = 100, Circle dataset, 0.2 noise level, 10000 observations\n",
      "570) svm, gamma = 1000, Circle dataset, 0.2 noise level, 10000 observations\n",
      "571) svm, gamma = 0.001, Circle dataset, 0.3 noise level, 10000 observations\n",
      "572) svm, gamma = 0.005, Circle dataset, 0.3 noise level, 10000 observations\n",
      "573) svm, gamma = 0.01, Circle dataset, 0.3 noise level, 10000 observations\n",
      "574) svm, gamma = 0.1, Circle dataset, 0.3 noise level, 10000 observations\n",
      "575) svm, gamma = 0.5, Circle dataset, 0.3 noise level, 10000 observations\n",
      "576) svm, gamma = 1, Circle dataset, 0.3 noise level, 10000 observations\n",
      "577) svm, gamma = 5, Circle dataset, 0.3 noise level, 10000 observations\n",
      "578) svm, gamma = 10, Circle dataset, 0.3 noise level, 10000 observations\n",
      "579) svm, gamma = 100, Circle dataset, 0.3 noise level, 10000 observations\n",
      "580) svm, gamma = 1000, Circle dataset, 0.3 noise level, 10000 observations\n",
      "581) svm, gamma = 0.001, Circle dataset, 0.4 noise level, 10000 observations\n",
      "582) svm, gamma = 0.005, Circle dataset, 0.4 noise level, 10000 observations\n",
      "583) svm, gamma = 0.01, Circle dataset, 0.4 noise level, 10000 observations\n",
      "584) svm, gamma = 0.1, Circle dataset, 0.4 noise level, 10000 observations\n",
      "585) svm, gamma = 0.5, Circle dataset, 0.4 noise level, 10000 observations\n",
      "586) svm, gamma = 1, Circle dataset, 0.4 noise level, 10000 observations\n",
      "587) svm, gamma = 5, Circle dataset, 0.4 noise level, 10000 observations\n",
      "588) svm, gamma = 10, Circle dataset, 0.4 noise level, 10000 observations\n",
      "589) svm, gamma = 100, Circle dataset, 0.4 noise level, 10000 observations\n",
      "590) svm, gamma = 1000, Circle dataset, 0.4 noise level, 10000 observations\n",
      "591) svm, gamma = 0.001, Circle dataset, 0.5 noise level, 10000 observations\n",
      "592) svm, gamma = 0.005, Circle dataset, 0.5 noise level, 10000 observations\n",
      "593) svm, gamma = 0.01, Circle dataset, 0.5 noise level, 10000 observations\n",
      "594) svm, gamma = 0.1, Circle dataset, 0.5 noise level, 10000 observations\n",
      "595) svm, gamma = 0.5, Circle dataset, 0.5 noise level, 10000 observations\n",
      "596) svm, gamma = 1, Circle dataset, 0.5 noise level, 10000 observations\n",
      "597) svm, gamma = 5, Circle dataset, 0.5 noise level, 10000 observations\n",
      "598) svm, gamma = 10, Circle dataset, 0.5 noise level, 10000 observations\n",
      "599) svm, gamma = 100, Circle dataset, 0.5 noise level, 10000 observations\n",
      "600) svm, gamma = 1000, Circle dataset, 0.5 noise level, 10000 observations\n",
      "211) logit, C = 0.001, Circle dataset, 0 noise level, 10 observations\n",
      "212) logit, C = 0.01, Circle dataset, 0 noise level, 10 observations\n",
      "213) logit, C = 0.1, Circle dataset, 0 noise level, 10 observations\n",
      "214) logit, C = 1, Circle dataset, 0 noise level, 10 observations\n",
      "215) logit, C = 10, Circle dataset, 0 noise level, 10 observations\n",
      "216) logit, C = 100, Circle dataset, 0 noise level, 10 observations\n",
      "217) logit, C = 1000, Circle dataset, 0 noise level, 10 observations\n",
      "218) logit, C = 0.001, Circle dataset, 0.1 noise level, 10 observations\n",
      "219) logit, C = 0.01, Circle dataset, 0.1 noise level, 10 observations\n",
      "220) logit, C = 0.1, Circle dataset, 0.1 noise level, 10 observations\n",
      "221) logit, C = 1, Circle dataset, 0.1 noise level, 10 observations\n",
      "222) logit, C = 10, Circle dataset, 0.1 noise level, 10 observations\n",
      "223) logit, C = 100, Circle dataset, 0.1 noise level, 10 observations\n",
      "224) logit, C = 1000, Circle dataset, 0.1 noise level, 10 observations\n",
      "225) logit, C = 0.001, Circle dataset, 0.2 noise level, 10 observations\n",
      "226) logit, C = 0.01, Circle dataset, 0.2 noise level, 10 observations\n",
      "227) logit, C = 0.1, Circle dataset, 0.2 noise level, 10 observations\n",
      "228) logit, C = 1, Circle dataset, 0.2 noise level, 10 observations\n",
      "229) logit, C = 10, Circle dataset, 0.2 noise level, 10 observations\n",
      "230) logit, C = 100, Circle dataset, 0.2 noise level, 10 observations\n",
      "231) logit, C = 1000, Circle dataset, 0.2 noise level, 10 observations\n",
      "232) logit, C = 0.001, Circle dataset, 0.3 noise level, 10 observations\n",
      "233) logit, C = 0.01, Circle dataset, 0.3 noise level, 10 observations\n",
      "234) logit, C = 0.1, Circle dataset, 0.3 noise level, 10 observations\n",
      "235) logit, C = 1, Circle dataset, 0.3 noise level, 10 observations\n",
      "236) logit, C = 10, Circle dataset, 0.3 noise level, 10 observations\n",
      "237) logit, C = 100, Circle dataset, 0.3 noise level, 10 observations\n",
      "238) logit, C = 1000, Circle dataset, 0.3 noise level, 10 observations\n",
      "239) logit, C = 0.001, Circle dataset, 0.4 noise level, 10 observations\n",
      "240) logit, C = 0.01, Circle dataset, 0.4 noise level, 10 observations\n",
      "241) logit, C = 0.1, Circle dataset, 0.4 noise level, 10 observations\n",
      "242) logit, C = 1, Circle dataset, 0.4 noise level, 10 observations\n",
      "243) logit, C = 10, Circle dataset, 0.4 noise level, 10 observations\n",
      "244) logit, C = 100, Circle dataset, 0.4 noise level, 10 observations\n",
      "245) logit, C = 1000, Circle dataset, 0.4 noise level, 10 observations\n",
      "246) logit, C = 0.001, Circle dataset, 0.5 noise level, 10 observations\n",
      "247) logit, C = 0.01, Circle dataset, 0.5 noise level, 10 observations\n",
      "248) logit, C = 0.1, Circle dataset, 0.5 noise level, 10 observations\n",
      "249) logit, C = 1, Circle dataset, 0.5 noise level, 10 observations\n",
      "250) logit, C = 10, Circle dataset, 0.5 noise level, 10 observations\n",
      "251) logit, C = 100, Circle dataset, 0.5 noise level, 10 observations\n",
      "252) logit, C = 1000, Circle dataset, 0.5 noise level, 10 observations\n",
      "253) logit, C = 0.001, Circle dataset, 0 noise level, 50 observations\n",
      "254) logit, C = 0.01, Circle dataset, 0 noise level, 50 observations\n",
      "255) logit, C = 0.1, Circle dataset, 0 noise level, 50 observations\n",
      "256) logit, C = 1, Circle dataset, 0 noise level, 50 observations\n",
      "257) logit, C = 10, Circle dataset, 0 noise level, 50 observations\n",
      "258) logit, C = 100, Circle dataset, 0 noise level, 50 observations\n",
      "259) logit, C = 1000, Circle dataset, 0 noise level, 50 observations\n",
      "260) logit, C = 0.001, Circle dataset, 0.1 noise level, 50 observations\n",
      "261) logit, C = 0.01, Circle dataset, 0.1 noise level, 50 observations\n",
      "262) logit, C = 0.1, Circle dataset, 0.1 noise level, 50 observations\n",
      "263) logit, C = 1, Circle dataset, 0.1 noise level, 50 observations\n",
      "264) logit, C = 10, Circle dataset, 0.1 noise level, 50 observations\n",
      "265) logit, C = 100, Circle dataset, 0.1 noise level, 50 observations\n",
      "266) logit, C = 1000, Circle dataset, 0.1 noise level, 50 observations\n",
      "267) logit, C = 0.001, Circle dataset, 0.2 noise level, 50 observations\n",
      "268) logit, C = 0.01, Circle dataset, 0.2 noise level, 50 observations\n",
      "269) logit, C = 0.1, Circle dataset, 0.2 noise level, 50 observations\n",
      "270) logit, C = 1, Circle dataset, 0.2 noise level, 50 observations\n",
      "271) logit, C = 10, Circle dataset, 0.2 noise level, 50 observations\n",
      "272) logit, C = 100, Circle dataset, 0.2 noise level, 50 observations\n",
      "273) logit, C = 1000, Circle dataset, 0.2 noise level, 50 observations\n",
      "274) logit, C = 0.001, Circle dataset, 0.3 noise level, 50 observations\n",
      "275) logit, C = 0.01, Circle dataset, 0.3 noise level, 50 observations\n",
      "276) logit, C = 0.1, Circle dataset, 0.3 noise level, 50 observations\n",
      "277) logit, C = 1, Circle dataset, 0.3 noise level, 50 observations\n",
      "278) logit, C = 10, Circle dataset, 0.3 noise level, 50 observations\n",
      "279) logit, C = 100, Circle dataset, 0.3 noise level, 50 observations\n",
      "280) logit, C = 1000, Circle dataset, 0.3 noise level, 50 observations\n",
      "281) logit, C = 0.001, Circle dataset, 0.4 noise level, 50 observations\n",
      "282) logit, C = 0.01, Circle dataset, 0.4 noise level, 50 observations\n",
      "283) logit, C = 0.1, Circle dataset, 0.4 noise level, 50 observations\n",
      "284) logit, C = 1, Circle dataset, 0.4 noise level, 50 observations\n",
      "285) logit, C = 10, Circle dataset, 0.4 noise level, 50 observations\n",
      "286) logit, C = 100, Circle dataset, 0.4 noise level, 50 observations\n",
      "287) logit, C = 1000, Circle dataset, 0.4 noise level, 50 observations\n",
      "288) logit, C = 0.001, Circle dataset, 0.5 noise level, 50 observations\n",
      "289) logit, C = 0.01, Circle dataset, 0.5 noise level, 50 observations\n",
      "290) logit, C = 0.1, Circle dataset, 0.5 noise level, 50 observations\n",
      "291) logit, C = 1, Circle dataset, 0.5 noise level, 50 observations\n",
      "292) logit, C = 10, Circle dataset, 0.5 noise level, 50 observations\n",
      "293) logit, C = 100, Circle dataset, 0.5 noise level, 50 observations\n",
      "294) logit, C = 1000, Circle dataset, 0.5 noise level, 50 observations\n",
      "295) logit, C = 0.001, Circle dataset, 0 noise level, 100 observations\n",
      "296) logit, C = 0.01, Circle dataset, 0 noise level, 100 observations\n",
      "297) logit, C = 0.1, Circle dataset, 0 noise level, 100 observations\n",
      "298) logit, C = 1, Circle dataset, 0 noise level, 100 observations\n",
      "299) logit, C = 10, Circle dataset, 0 noise level, 100 observations\n",
      "300) logit, C = 100, Circle dataset, 0 noise level, 100 observations\n",
      "301) logit, C = 1000, Circle dataset, 0 noise level, 100 observations\n",
      "302) logit, C = 0.001, Circle dataset, 0.1 noise level, 100 observations\n",
      "303) logit, C = 0.01, Circle dataset, 0.1 noise level, 100 observations\n",
      "304) logit, C = 0.1, Circle dataset, 0.1 noise level, 100 observations\n",
      "305) logit, C = 1, Circle dataset, 0.1 noise level, 100 observations\n",
      "306) logit, C = 10, Circle dataset, 0.1 noise level, 100 observations\n",
      "307) logit, C = 100, Circle dataset, 0.1 noise level, 100 observations\n",
      "308) logit, C = 1000, Circle dataset, 0.1 noise level, 100 observations\n",
      "309) logit, C = 0.001, Circle dataset, 0.2 noise level, 100 observations\n",
      "310) logit, C = 0.01, Circle dataset, 0.2 noise level, 100 observations\n",
      "311) logit, C = 0.1, Circle dataset, 0.2 noise level, 100 observations\n",
      "312) logit, C = 1, Circle dataset, 0.2 noise level, 100 observations\n",
      "313) logit, C = 10, Circle dataset, 0.2 noise level, 100 observations\n",
      "314) logit, C = 100, Circle dataset, 0.2 noise level, 100 observations\n",
      "315) logit, C = 1000, Circle dataset, 0.2 noise level, 100 observations\n",
      "316) logit, C = 0.001, Circle dataset, 0.3 noise level, 100 observations\n",
      "317) logit, C = 0.01, Circle dataset, 0.3 noise level, 100 observations\n",
      "318) logit, C = 0.1, Circle dataset, 0.3 noise level, 100 observations\n",
      "319) logit, C = 1, Circle dataset, 0.3 noise level, 100 observations\n",
      "320) logit, C = 10, Circle dataset, 0.3 noise level, 100 observations\n",
      "321) logit, C = 100, Circle dataset, 0.3 noise level, 100 observations\n",
      "322) logit, C = 1000, Circle dataset, 0.3 noise level, 100 observations\n",
      "323) logit, C = 0.001, Circle dataset, 0.4 noise level, 100 observations\n",
      "324) logit, C = 0.01, Circle dataset, 0.4 noise level, 100 observations\n",
      "325) logit, C = 0.1, Circle dataset, 0.4 noise level, 100 observations\n",
      "326) logit, C = 1, Circle dataset, 0.4 noise level, 100 observations\n",
      "327) logit, C = 10, Circle dataset, 0.4 noise level, 100 observations\n",
      "328) logit, C = 100, Circle dataset, 0.4 noise level, 100 observations\n",
      "329) logit, C = 1000, Circle dataset, 0.4 noise level, 100 observations\n",
      "330) logit, C = 0.001, Circle dataset, 0.5 noise level, 100 observations\n",
      "331) logit, C = 0.01, Circle dataset, 0.5 noise level, 100 observations\n",
      "332) logit, C = 0.1, Circle dataset, 0.5 noise level, 100 observations\n",
      "333) logit, C = 1, Circle dataset, 0.5 noise level, 100 observations\n",
      "334) logit, C = 10, Circle dataset, 0.5 noise level, 100 observations\n",
      "335) logit, C = 100, Circle dataset, 0.5 noise level, 100 observations\n",
      "336) logit, C = 1000, Circle dataset, 0.5 noise level, 100 observations\n",
      "337) logit, C = 0.001, Circle dataset, 0 noise level, 1000 observations\n",
      "338) logit, C = 0.01, Circle dataset, 0 noise level, 1000 observations\n",
      "339) logit, C = 0.1, Circle dataset, 0 noise level, 1000 observations\n",
      "340) logit, C = 1, Circle dataset, 0 noise level, 1000 observations\n",
      "341) logit, C = 10, Circle dataset, 0 noise level, 1000 observations\n",
      "342) logit, C = 100, Circle dataset, 0 noise level, 1000 observations\n",
      "343) logit, C = 1000, Circle dataset, 0 noise level, 1000 observations\n",
      "344) logit, C = 0.001, Circle dataset, 0.1 noise level, 1000 observations\n",
      "345) logit, C = 0.01, Circle dataset, 0.1 noise level, 1000 observations\n",
      "346) logit, C = 0.1, Circle dataset, 0.1 noise level, 1000 observations\n",
      "347) logit, C = 1, Circle dataset, 0.1 noise level, 1000 observations\n",
      "348) logit, C = 10, Circle dataset, 0.1 noise level, 1000 observations\n",
      "349) logit, C = 100, Circle dataset, 0.1 noise level, 1000 observations\n",
      "350) logit, C = 1000, Circle dataset, 0.1 noise level, 1000 observations\n",
      "351) logit, C = 0.001, Circle dataset, 0.2 noise level, 1000 observations\n",
      "352) logit, C = 0.01, Circle dataset, 0.2 noise level, 1000 observations\n",
      "353) logit, C = 0.1, Circle dataset, 0.2 noise level, 1000 observations\n",
      "354) logit, C = 1, Circle dataset, 0.2 noise level, 1000 observations\n",
      "355) logit, C = 10, Circle dataset, 0.2 noise level, 1000 observations\n",
      "356) logit, C = 100, Circle dataset, 0.2 noise level, 1000 observations\n",
      "357) logit, C = 1000, Circle dataset, 0.2 noise level, 1000 observations\n",
      "358) logit, C = 0.001, Circle dataset, 0.3 noise level, 1000 observations\n",
      "359) logit, C = 0.01, Circle dataset, 0.3 noise level, 1000 observations\n",
      "360) logit, C = 0.1, Circle dataset, 0.3 noise level, 1000 observations\n",
      "361) logit, C = 1, Circle dataset, 0.3 noise level, 1000 observations\n",
      "362) logit, C = 10, Circle dataset, 0.3 noise level, 1000 observations\n",
      "363) logit, C = 100, Circle dataset, 0.3 noise level, 1000 observations\n",
      "364) logit, C = 1000, Circle dataset, 0.3 noise level, 1000 observations\n",
      "365) logit, C = 0.001, Circle dataset, 0.4 noise level, 1000 observations\n",
      "366) logit, C = 0.01, Circle dataset, 0.4 noise level, 1000 observations\n",
      "367) logit, C = 0.1, Circle dataset, 0.4 noise level, 1000 observations\n",
      "368) logit, C = 1, Circle dataset, 0.4 noise level, 1000 observations\n",
      "369) logit, C = 10, Circle dataset, 0.4 noise level, 1000 observations\n",
      "370) logit, C = 100, Circle dataset, 0.4 noise level, 1000 observations\n",
      "371) logit, C = 1000, Circle dataset, 0.4 noise level, 1000 observations\n",
      "372) logit, C = 0.001, Circle dataset, 0.5 noise level, 1000 observations\n",
      "373) logit, C = 0.01, Circle dataset, 0.5 noise level, 1000 observations\n",
      "374) logit, C = 0.1, Circle dataset, 0.5 noise level, 1000 observations\n",
      "375) logit, C = 1, Circle dataset, 0.5 noise level, 1000 observations\n",
      "376) logit, C = 10, Circle dataset, 0.5 noise level, 1000 observations\n",
      "377) logit, C = 100, Circle dataset, 0.5 noise level, 1000 observations\n",
      "378) logit, C = 1000, Circle dataset, 0.5 noise level, 1000 observations\n",
      "379) logit, C = 0.001, Circle dataset, 0 noise level, 10000 observations\n",
      "380) logit, C = 0.01, Circle dataset, 0 noise level, 10000 observations\n",
      "381) logit, C = 0.1, Circle dataset, 0 noise level, 10000 observations\n",
      "382) logit, C = 1, Circle dataset, 0 noise level, 10000 observations\n",
      "383) logit, C = 10, Circle dataset, 0 noise level, 10000 observations\n",
      "384) logit, C = 100, Circle dataset, 0 noise level, 10000 observations\n",
      "385) logit, C = 1000, Circle dataset, 0 noise level, 10000 observations\n",
      "386) logit, C = 0.001, Circle dataset, 0.1 noise level, 10000 observations\n",
      "387) logit, C = 0.01, Circle dataset, 0.1 noise level, 10000 observations\n",
      "388) logit, C = 0.1, Circle dataset, 0.1 noise level, 10000 observations\n",
      "389) logit, C = 1, Circle dataset, 0.1 noise level, 10000 observations\n",
      "390) logit, C = 10, Circle dataset, 0.1 noise level, 10000 observations\n",
      "391) logit, C = 100, Circle dataset, 0.1 noise level, 10000 observations\n",
      "392) logit, C = 1000, Circle dataset, 0.1 noise level, 10000 observations\n",
      "393) logit, C = 0.001, Circle dataset, 0.2 noise level, 10000 observations\n",
      "394) logit, C = 0.01, Circle dataset, 0.2 noise level, 10000 observations\n",
      "395) logit, C = 0.1, Circle dataset, 0.2 noise level, 10000 observations\n",
      "396) logit, C = 1, Circle dataset, 0.2 noise level, 10000 observations\n",
      "397) logit, C = 10, Circle dataset, 0.2 noise level, 10000 observations\n",
      "398) logit, C = 100, Circle dataset, 0.2 noise level, 10000 observations\n",
      "399) logit, C = 1000, Circle dataset, 0.2 noise level, 10000 observations\n",
      "400) logit, C = 0.001, Circle dataset, 0.3 noise level, 10000 observations\n",
      "401) logit, C = 0.01, Circle dataset, 0.3 noise level, 10000 observations\n",
      "402) logit, C = 0.1, Circle dataset, 0.3 noise level, 10000 observations\n",
      "403) logit, C = 1, Circle dataset, 0.3 noise level, 10000 observations\n",
      "404) logit, C = 10, Circle dataset, 0.3 noise level, 10000 observations\n",
      "405) logit, C = 100, Circle dataset, 0.3 noise level, 10000 observations\n",
      "406) logit, C = 1000, Circle dataset, 0.3 noise level, 10000 observations\n",
      "407) logit, C = 0.001, Circle dataset, 0.4 noise level, 10000 observations\n",
      "408) logit, C = 0.01, Circle dataset, 0.4 noise level, 10000 observations\n",
      "409) logit, C = 0.1, Circle dataset, 0.4 noise level, 10000 observations\n",
      "410) logit, C = 1, Circle dataset, 0.4 noise level, 10000 observations\n",
      "411) logit, C = 10, Circle dataset, 0.4 noise level, 10000 observations\n",
      "412) logit, C = 100, Circle dataset, 0.4 noise level, 10000 observations\n",
      "413) logit, C = 1000, Circle dataset, 0.4 noise level, 10000 observations\n",
      "414) logit, C = 0.001, Circle dataset, 0.5 noise level, 10000 observations\n",
      "415) logit, C = 0.01, Circle dataset, 0.5 noise level, 10000 observations\n",
      "416) logit, C = 0.1, Circle dataset, 0.5 noise level, 10000 observations\n",
      "417) logit, C = 1, Circle dataset, 0.5 noise level, 10000 observations\n",
      "418) logit, C = 10, Circle dataset, 0.5 noise level, 10000 observations\n",
      "419) logit, C = 100, Circle dataset, 0.5 noise level, 10000 observations\n",
      "420) logit, C = 1000, Circle dataset, 0.5 noise level, 10000 observations\n"
     ]
    }
   ],
   "source": [
    "count_svm = 0\n",
    "count_logit = 0\n",
    "\n",
    "for ds in ds_name:\n",
    "    for clf in clfs:\n",
    "        for n in n_samples:\n",
    "            for nl in noise_level:\n",
    "                temp_df = df.query('ds_name == @ds and noise_level == @nl').head(n)\n",
    "                \n",
    "                if clf == 'svm':\n",
    "                    for gamma in gammas:\n",
    "                        svm_clf = svm.SVC(kernel = 'rbf', gamma = gamma)\n",
    "                        score = cross_validate(svm_clf, temp_df[['x', 'y']], temp_df['label'], cv = k_fold, return_train_score = True)\n",
    "                        TRE_mean, TRE_std = score['train_score'].mean(), score['train_score'].std()\n",
    "                        TESTE_mean, TESTE_std = score['test_score'].mean(), score['test_score'].std()\n",
    "                        E_DIFF = TRE_mean - TESTE_mean\n",
    "                        result.append((ds, n, nl, clf, 5, TRE_mean, TRE_std, TESTE_mean, TESTE_std, E_DIFF, gamma))\n",
    "                        count_svm = count_svm + 1\n",
    "                        print(f'{count_svm}) {clf}, gamma = {gamma}, {ds} dataset, {nl} noise level, {n} observations')\n",
    "                \n",
    "                elif clf == 'logit':\n",
    "                    for c in cs:\n",
    "                        logit = LogisticRegression(penalty = 'l2', C = c)\n",
    "                        score = cross_validate(logit, temp_df[['x', 'y']], temp_df['label'], cv = k_fold, return_train_score = True)\n",
    "                        TRE_mean, TRE_std = score['train_score'].mean(), score['train_score'].std()\n",
    "                        TESTE_mean, TESTE_std = score['test_score'].mean(), score['test_score'].std()\n",
    "                        E_DIFF = TRE_mean - TESTE_mean\n",
    "                        result.append((ds, n, nl, clf, 5, TRE_mean, TRE_std, TESTE_mean, TESTE_std, E_DIFF, c))\n",
    "                        count_logit = count_logit + 1\n",
    "                        print(f'{count_logit}) {clf}, C = {c}, {ds} dataset, {nl} noise level, {n} observations')\n",
    "\n",
    "                '''\n",
    "                # Note: K neighbors than 9 can not be run with 10 observations sample and 5-Folds Cross Validation. therefore, we will set the K neighbors running until 7 only.\n",
    "                elif clf == 'knn':\n",
    "                    for k in range(1,20,2): # See Note above.\n",
    "                        # print(f'Running {clf} model with K Nearest Neighbors: {k}, for {ds} dataset with {nl} noise level, substeted for {n} observations')\n",
    "                        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "                        score = cross_validate(knn, temp_df[['x', 'y']], temp_df['label'], cv = k_fold, return_train_score = True)\n",
    "                        TRE = score['train_score'].mean()\n",
    "                        TESTE = score['test_score'].mean()\n",
    "                        E_DIFF = TRE - TESTE\n",
    "                        result.append((ds, n, nl, clf, 5, TRE, TESTE, E_DIFF, k))\n",
    "                '''\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3beeacc3-9425-4628-8e0e-e5461bbfd4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 11)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result, columns = ['ds', 'n', 'nl', 'clf', 'KFolds', 'TRE_mean', 'TRE_std', 'TESTE_mean', 'TESTE_std', 'E_DIFF', 'Regularization'])\n",
    "result_df['E_DIFF'] = result_df.TESTE_mean - result_df.TRE_mean\n",
    "result_df = result_df.tail(1020)\n",
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "bad1467c-33ee-4013-ac34-a1effe961410",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('Result DataFrame - Modeling Exercise 20_04_2022.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4220c1d7-4162-4763-9fd0-d1f2081b6dd8",
   "metadata": {},
   "source": [
    "### 3. Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fcdc44-35a1-4b60-91c5-b385ddcbd965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>n</th>\n",
       "      <th>nl</th>\n",
       "      <th>clf</th>\n",
       "      <th>KFolds</th>\n",
       "      <th>TRE_mean</th>\n",
       "      <th>TRE_std</th>\n",
       "      <th>TESTE_mean</th>\n",
       "      <th>TESTE_std</th>\n",
       "      <th>E_DIFF</th>\n",
       "      <th>Regularization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moon</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moon</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moon</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moon</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moon</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>svm</td>\n",
       "      <td>5</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ds   n   nl  clf  KFolds  TRE_mean   TRE_std  TESTE_mean  TESTE_std  \\\n",
       "0  Moon  10  0.0  svm       5     0.675  0.100000         0.5   0.000000   \n",
       "1  Moon  10  0.0  svm       5     0.675  0.100000         0.5   0.000000   \n",
       "2  Moon  10  0.0  svm       5     0.675  0.100000         0.5   0.000000   \n",
       "3  Moon  10  0.0  svm       5     0.750  0.158114         0.5   0.000000   \n",
       "4  Moon  10  0.0  svm       5     0.850  0.122474         0.8   0.244949   \n",
       "\n",
       "   E_DIFF  Regularization  \n",
       "0  -0.175           0.001  \n",
       "1  -0.175           0.005  \n",
       "2  -0.175           0.010  \n",
       "3  -0.250           0.100  \n",
       "4  -0.050           0.500  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_copy = pd.read_csv('Data/Result DataFrame - Modeling Exercise 20_04_2022.csv')\n",
    "result_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfeeaf9-c613-47ce-8607-e29997bfc8ec",
   "metadata": {},
   "source": [
    "#### 3.1) For SVM only, For dataset of size 10k and for each dataset, What are the best model params? How stable is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "85e78cb7-8fef-4d0e-abce-b059a78b5d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ds      nl \n",
       "Circle  0.0    1.000000\n",
       "        0.1    0.871325\n",
       "        0.2    0.799450\n",
       "        0.3    0.811025\n",
       "        0.4    0.833550\n",
       "        0.5    0.841975\n",
       "Moon    0.0    1.000000\n",
       "        0.1    0.999950\n",
       "        0.2    0.982925\n",
       "        0.3    0.942175\n",
       "        0.4    0.917350\n",
       "        0.5    0.906525\n",
       "Name: TRE_mean, dtype: float64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_copy.query('clf == \"svm\" and n == 10000').groupby(['ds', 'nl']).TRE_mean.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0dafea94-56b9-4ea5-a949-55c1981bdf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afd110e8a204d39ac66e94b8b149f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='noise_level', options=(0, 0.1, 0.2, 0.3, 0.4, 0.5), value=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def show_fig31(noise_level = widgets.SelectionSlider(options = [0, 0.1, 0.2, 0.3, 0.4, 0.5])):\n",
    "    df = result_df_copy.query('clf == \"svm\" and n == 10000').reset_index()\n",
    "    df = df.query('nl == @noise_level')\n",
    "    df['Dataset Type'], df['Gamma'], df['Accuracy'] = df.ds, df.Regularization.apply(lambda n: str(n)), df.TESTE_mean.apply(lambda s: s * 100)\n",
    "    fig31 = px.bar(df,\n",
    "                       x = 'Gamma',\n",
    "                       y = 'Accuracy',\n",
    "                       color = 'Dataset Type',\n",
    "                       barmode='group',\n",
    "                       text_auto = '.2s',\n",
    "                       range_y = [0,100],\n",
    "                       title = f'Accuracy Test Score by Gamma Values for SVM Model for Smaples Size of 10,000 with {noise_level} Noise Level.')\n",
    "    fig31.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\n",
    "    return fig31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6896c5-d72d-461c-9221-173a08c0fc23",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Answer 3.1:** For all Noise level and for both Datasets (Circle and Moon), the Hyper Parameter that provides the best results (max TESTE) is **gamma = 1,000**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208715e-3e1e-4e6b-b81a-f29e36e2d216",
   "metadata": {},
   "source": [
    "#### 3.2) For SVM only, For dataset of size 10k and for each dataset, What is the most stable model and model params? How good is it in comparison to other models? Explain using bias and variance terminoligy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1192cf41-0d0b-4380-980f-27d8c62d2ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8f476d8e5a43f6812b74faf9ad8f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='ds', options=('Moon', 'Circle'), value='Moon'), Output()), _do…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def show_fig32(ds = widgets.RadioButtons(options =result_df_copy.ds.unique())):\n",
    "    df = result_df_copy.query('ds == @ds and clf == \"svm\" and n == 10000')\n",
    "    df['Accuracy'] = df.TESTE_mean.apply(lambda s: s * 100)\n",
    "    df['Test_Standard_Deviation'] = df.TESTE_std.apply(lambda s: s * 100)\n",
    "    df['Regularization'] = df.Regularization.apply(lambda s: str(s))\n",
    "    fig32  = px.line(df, x = 'Regularization', y = ['Test_Standard_Deviation'], color = 'nl', width = 1000, height = 600)\n",
    "    return fig32.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37d87b-bf6f-4ac3-8f17-81c5e19abce1",
   "metadata": {},
   "source": [
    "**ANSWER 3.2:** For SVM Model, for data size of 10,000 and for both datasets, as the Regularization increases the Variance (STD) reduces, for most of noise levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32883d0b-d073-403e-8a9d-852b33efcaea",
   "metadata": {},
   "source": [
    "#### 3.3) Does regularization help for linear models? consider different datasets sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "af33c810-1223-4117-b13a-d00306b17015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accc65b9a2294e05a907b7a529f8774b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='ds', options=('Moon', 'Circle'), value='Moon'), Output()), _do…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def show_fig33(ds = widgets.RadioButtons(options =result_df_copy.ds.unique())):\n",
    "    df = result_df_copy.query('clf == \"logit\" and ds == @ds')\n",
    "    df['Regularization'], df['Accuracy Test Score'] = df.Regularization.apply(lambda s: str(s)), df.TESTE_mean.apply(lambda s: s * 100)\n",
    "    return px.bar(df,\n",
    "                  x = 'Regularization',\n",
    "                  y = 'Accuracy Test Score',\n",
    "                  facet_col = 'n',\n",
    "                  facet_row= 'nl',\n",
    "                  width = 1250,\n",
    "                  height = 1250,\n",
    "                  range_y = [0,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4cb85-15dc-4fd8-acec-6ebec7869e6d",
   "metadata": {},
   "source": [
    "**Answer 3.3:** Generally, for both datasets, Moons, and Circles, Regularization does NOT improve the Accuracy received for all noise levels. The Reason might be that in first place Logistic Regression as a Linear Model is a Low Capacity Model. Therefore, regularization, that makes the model less comlex, doesn't help improving the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335ceb0-ac5c-474e-a510-9800a3c084d7",
   "metadata": {},
   "source": [
    "#### 3.4) For a given noise level of your chioce, How does the train, test and difference error changes with increasing data sizes? (answer for svm and LR seperatly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "45db94dc-9b00-4d17-aeb0-c5a41225b7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa939252f91b4114a9fba1fae1206f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='ds', options=('Moon', 'Circle'), value='Moon'), RadioButtons(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def show_fig34(ds = widgets.RadioButtons(options =result_df_copy.ds.unique()), clf = widgets.RadioButtons(options =result_df_copy.clf.unique())):\n",
    "    df = result_df_copy.query('ds == @ds and clf == @clf and nl == 0 and Regularization == 0.1')\n",
    "    df['n'] = df.n.apply(lambda s: str(s))\n",
    "    df['Accuracy Test Score'] = df.TESTE_mean.apply(lambda s: s * 100)\n",
    "    df['Accuracy Train Score'] = df.TRE_mean.apply(lambda s: s * 100)\n",
    "    df['Difference'] = df.E_DIFF.apply(lambda s: s * 100)\n",
    "    fig34  = px.scatter(df, x = 'n', y = ['Accuracy Test Score', 'Accuracy Train Score', 'Difference'], range_y = [-50,150],\n",
    "                         title = f'The Conection Between Test and Train Accuracy and their Difference to The Sample Size for {clf} Model, Noise Level of 0, Regulariztion (C and Gamma) of 0.1')\n",
    "    return fig34.show()\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ed87e-408f-4f19-8b88-d2c1ede3d7a3",
   "metadata": {},
   "source": [
    "**Answer 3.4** For Noise Level 0.0, For both Classifier Models (logit and SVM), and for both Datasets (Moons and Circles) with Regularization c = 0.1 and gamma = 0.1, the Different between the Test-score and Train-score decreases as the data size increases. It means that the Overfitting received for smaller size data is being gone as the number of samples increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a613271-b300-4e16-9a18-a7f700eff2d6",
   "metadata": {},
   "source": [
    "#### 3.5) For a given noise level of your chioce, How does the train, test and difference error changes with increasing model complexity? (answer for svm and LR seperatly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "24c38a25-8904-4500-a52e-4e754c01a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6213fa5fd3e4434ea4a743af4a2e9dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def show_fig35():\n",
    "    df = result_df_copy.query('nl == 0.5 and n == 10000')\n",
    "    df['Regularization'] = df.Regularization.apply(lambda s: str(s))\n",
    "    df['Accuracy Test Score'] = df.TESTE_mean.apply(lambda s: s * 100)\n",
    "    df['Accuracy Train Score'] = df.TRE_mean.apply(lambda s: s * 100)\n",
    "    df['Difference'] = df.E_DIFF.apply(lambda s: s * 100)\n",
    "    fig35 = px.scatter(df,\n",
    "                       x = 'Regularization',\n",
    "                       y = ['Accuracy Test Score', 'Accuracy Train Score', 'Difference'],\n",
    "                       facet_row = 'clf',\n",
    "                       facet_col = 'ds',\n",
    "                       range_y = [-50,150],\n",
    "                       height = 1000,\n",
    "                       width = 1250)\n",
    "    return fig35.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c203ae-da5b-47d2-a0af-30399145748d",
   "metadata": {},
   "source": [
    "**Answer 3.5:** For noise level 0.5, data size 10,000, Logistic Regression's Train and Test stay close (around 0 Difference) consistently as Regularization increases. A posible reason is that LR is a Low Comlexity Models by defult. For SMV Model, the Difference reduses as the regularization increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1eaa4-e5ea-4069-8aa0-88d8fe0866d2",
   "metadata": {},
   "source": [
    "#### 3.6) Does the Noise Level (NL) effect the number of datapoints needed to reach optimal test results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5027c859-9337-44d1-9e86-27b60dc6cd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c700ee3d5ac4e9a94600b91233f6d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='ds', options=('Moon', 'Circle'), value='Moon'), RadioButtons(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact\n",
    "def fig36(ds = widgets.RadioButtons(options = result_df_copy.ds.unique()),\n",
    "          clf = widgets.RadioButtons(options = result_df_copy.clf.unique()),\n",
    "          reg = widgets.RadioButtons(options = result_df_copy.Regularization.unique())):\n",
    "    df = result_df_copy.query('ds == @ds and clf == @clf and Regularization == @reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5b58e-393d-4eb3-8bad-3a170276ad14",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Bonus:\n",
    "\n",
    "* For SVM: Select one dataset and with 0.2 noise level. Identify the optimal model params, and visualize the decision boundry learned. \n",
    "  * Hint: Use a grid. See classification models notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68124026-b4bc-4022-81ee-158175f9e732",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c6e0b-b513-4bb7-b39e-ae3baa5b3e68",
   "metadata": {
    "tags": []
   },
   "source": [
    "### More hints!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad0ce4-d598-4e30-ab43-dd9a064d8dd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you'll build the datasets dataframe correctly, you'll have **one** dataframe that has dataset_name and noise_level colmuns, as well as the regular x,y,label colmns. To unsure you've appended everything correctly, groupby the proper colmuns and look at the size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b5d99fc-102f-4b04-8962-1e85e8909cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use proper groupby statement to ensure the datasets dataframe contains data as expected. You should see the following result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e1094-232b-46f2-ba89-856e14fab58b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Your "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58ae49-7d87-462b-b681-61536ae4bca8",
   "metadata": {
    "tags": []
   },
   "source": [
    "You experiment code should look something like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6dca06-01af-437e-8eb1-d559cdb96741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3386946450.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/7_/rd00750d2c32fj3338594q200000gp/T/ipykernel_10126/3386946450.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    hp_range = <'Your hyper parameters ranges here'>\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "datasets_type = ['circles', 'moons']\n",
    "k_folds = 10\n",
    "n_samples = [10, 50, 100, 1000, 10000]\n",
    "noise_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "clf_types = ['log_reg', 'svm']\n",
    "hp_range = <'Your hyper parameters ranges here'>\n",
    "regularization_values = <'Your regularization values here'>\n",
    "results = []\n",
    "for ds_type in datasets_type:\n",
    "    print(f'Working on {ds_type}')\n",
    "    for nl in noise_levels:\n",
    "        for n in n_samples:\n",
    "            ds = datasets.query(<'your query here'>).head(n)\n",
    "            print(f'Starting {k_folds}-fold cross validation for {ds_type} datasets with {n} samples and noise level {nl}. Going to train {clf_types} classifiers.')\n",
    "            for k in range(k_folds):\n",
    "                X, Y = <'Your code here'>\n",
    "                x_train,x_test,y_train,y_test= <'Your code here'>\n",
    "                for clf_type in clf_types:\n",
    "                    if clf_type == 'log_reg':\n",
    "                        for regularization_value in regularization_values:\n",
    "                            train_acc, test_acc = <'Your code here'>\n",
    "                            results.append(<'Your code here'>)\n",
    "                    if clf_type == 'svm':\n",
    "                        for gamma in hp_range:\n",
    "                            train_acc, test_acc = <'Your code here'>\n",
    "                            results.append(<'Your code here'>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c757d2e-c9dc-4ca8-ad10-1b5b0b518681",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1 - Manual Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99abda-4f26-4331-90f3-4e95b971b70f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The purpose of this excercise is to examplify the need in a fitting algorithm. We will do so by trying to find only 2 models parameters by ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98898c9c-d06c-49c1-a5c3-7dc5e7f9e787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slope, intercept = 2.5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507c069-f14a-41a7-a526-1627c7453687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_1, x_2 = 0.2, 0.6\n",
    "on_line = [[x, x*slope + intercept,'on_line'] for x in np.linspace(-1,2,100)]\n",
    "\n",
    "above_line = [[x_1, x_1*slope + intercept + 2, 'Above'], \n",
    "              [x_2, x_2*slope + intercept + 2, 'Above']] \n",
    "\n",
    "below_line = [[x_1, x_1*slope + intercept - 2, 'Below'], \n",
    "              [x_2, x_2*slope + intercept - 2, 'Below']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ebc44-35aa-4d0a-b14f-4d0f96b8db6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['x','y','label']\n",
    "data = pd.DataFrame(on_line + above_line + below_line, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf258b-2747-49de-b575-5b0b4f4c436b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.scatter(data, x='x', y='y', color = 'label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
